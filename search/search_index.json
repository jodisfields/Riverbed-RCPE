{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Riverbed RCPE Professional \ud83d\udcda About Riverbed RCPE Professional: Implement WAN Optimization Course Notes and Discussion. This content is intended for personal reference and collaboration only! Name: RCPE Professional: Implement WAN Optimization Start: 22 May 2022 0700 AEST End: 27 May 2022 1600 AEST Instructor: Pat Robson Location: Zoom Reference Material Riverbed Lab Dashboard Course Specific Labs Technet Article Welcome and Logistics_RCPE-D Describe how WAN Optimization Works-D Describe the Solution Architecture-D Manage Your Appliances-D Control Optimization with In-path & Peering Rules-D Deploy the SteelCentral Controller for SteelHead-D Optimize HTTP Traffic-D Optimize SSL Traffic-D Customize Windows Traffic in an Active Directory Environment-D Optimize Other Application Layers-D Configure SteelHead SaaS Accelerator-D Describe SteelHead Cloud Solutions-D Monitor and Report on Solution Performance-D Course Summary-D \u26cf\ufe0f Built Using Mkdocs Mkdocs Material Markdown Git Python \ud83d\ude80 Deployment Before starting you need to have Git and Python installed. # Clone this project git clone https://github.com/jodisfields/Riverbed-RCPE.git # Access cd Riverbed-RCPE # Install dependencies pip install -r requirements.txt # Run the project mkdocs serve # Open in browser Navigate to http://localhost:8000 \ud83d\udcdd Acknowledgements Riverbed","title":"Home"},{"location":"#about","text":"Riverbed RCPE Professional: Implement WAN Optimization Course Notes and Discussion. This content is intended for personal reference and collaboration only! Name: RCPE Professional: Implement WAN Optimization Start: 22 May 2022 0700 AEST End: 27 May 2022 1600 AEST Instructor: Pat Robson Location: Zoom","title":"\ud83d\udcda About"},{"location":"#reference-material","text":"Riverbed Lab Dashboard Course Specific Labs Technet Article Welcome and Logistics_RCPE-D Describe how WAN Optimization Works-D Describe the Solution Architecture-D Manage Your Appliances-D Control Optimization with In-path & Peering Rules-D Deploy the SteelCentral Controller for SteelHead-D Optimize HTTP Traffic-D Optimize SSL Traffic-D Customize Windows Traffic in an Active Directory Environment-D Optimize Other Application Layers-D Configure SteelHead SaaS Accelerator-D Describe SteelHead Cloud Solutions-D Monitor and Report on Solution Performance-D Course Summary-D","title":"Reference Material"},{"location":"#built-using","text":"Mkdocs Mkdocs Material Markdown Git Python","title":"\u26cf\ufe0f Built Using"},{"location":"#deployment","text":"Before starting you need to have Git and Python installed. # Clone this project git clone https://github.com/jodisfields/Riverbed-RCPE.git # Access cd Riverbed-RCPE # Install dependencies pip install -r requirements.txt # Run the project mkdocs serve # Open in browser Navigate to http://localhost:8000","title":"\ud83d\ude80 Deployment"},{"location":"#acknowledgements","text":"Riverbed","title":"\ud83d\udcdd Acknowledgements"},{"location":"Kerberos/","text":"How does Kerberos work? Overview Kerberos is an authentication protocol, which means it is a prescribed method for a user to prove their identity to a particular application service over a network. The set of players in the protocol can be seen as: a client program acting on behalf of a user a centralized service, called the Authentication Server (AS) one or more application servers. Kerberos works by using the Authentication Server as a middle-man between clients and applications. The Authentication Server must have a priori knowledge of: all users in the system all application services in the system to allow a user known by the Authentication Server to prove their identity to an application service known by the Authentication Server. What does \"known by the Authentication Server\" mean? During the system's set-up, the Authentication Server must be informed about all users in the system. This means for each user, an account is created on the Authentication Server and given a password chosen by the user. The username, password, and the Kerberos version number are encrypted using an agreed-upon encryption scheme to produce a secret key for the user. Now, the user can use their username and password under the same encryption scheme to re-create their secret key from anywhere. The user can therefore send confidential messages to the Authentication Server over a network by encrypting the message with their secret key. Similarly, each application service must be issued a secret key that it can use to communicate with the Authentication Server over a network. The Basic Kerberos Protocol Note: in the diagrams below, colors are used to help clarify which segments are encrypted by which keys, since there are three keys involved, and it can get confusing. When a client wants to prove its identity to an application, it sends a message containing the user's username (in cleartext) and a request to authenticate to a particular application service (encrypted by the user's secret key) to the Authentication Server. The Authentication Server looks up the username to find the user's secret key and uses it to decrypt the request. The Authentication Server then creates a Kerberos ticket containing: a session key the session key expiration time the user's identity. The Authentication Server creates a response containing a cleartext version of the ticket AND a version of the ticket encrypted using the desired application service's secret key. The Authentication Server then encrypts the entire response using the user's shared key and sends it to the client. Now the client sends the application server a request containing: the Kerberos ticket encrypted by the application service's secret key (received from the Authentication Server) an \"authenticator\" encrypted by the session key containing the current time a checksum the user's identity and sends it to the application server. Finally, the application server decrypts the Kerberos ticket using its own secret key, and decrypts the authenticator using the session key from the ticket. The application server calculates the checksum for the request and checks if it matches the checksum in the authenticator. If it does, then the application server knows the same session key was used to encrypt the authenticator as to decrypt it, so the sender must have known the session key in the ticket. The application server then verifies the identity of the sender by checking that the identity in the ticket matches the identity in the authenticator. The client can optionally include a request that the application server also prove its identity. In this case, the application server sends a response encrypted by the session key (thereby proving that the application server was able to decrypt the ticket using its secret key). Single Sign-On (SSO) and Ticket Granting Tickets If the system contains a set of application services which a user should be able to access, it is desirable for the user to be able to authenticate just once rather than once for each service. A simple way to do this is to cache the user's password in memory, but a safer way is to use an extended version of the Kerberos protocol which caches only tickets and encryption keys for a limited time. When the user logs in, an authentication request for the ticket granting service is issued to the Authentication Server. The ticket that is returned is called the ticket granting ticket. The version of the ticket granting ticket encrypted by the ticket granting service's secret key is cached on the client, along with the session key from the ticket granting ticket. Now when the user accesses a new service (and therefore needs to authenticate to that service), a ticket for that service is requested from the Authentication Server via the ticket granting service. Using the Session Key for Further Communication As a by-product of the authentication protocol, the client and application server end up with a shared key that they can use to further exchange private encrypted messages. Sources Draws heavily from USC/ISI Technical Report number ISI/RS-94-399 Redmond Magazine Blog post by Lynn Root Further Reading Current Kerberos release from MIT Red Hat Enterprise Linux 3: Reference Guide, Chapter 18. Kerberos Set up Kerberos on FreeBSD Related Topics Public key cryptography and PGP","title":"How does Kerberos work?"},{"location":"Kerberos/#how-does-kerberos-work","text":"","title":"How does Kerberos work?"},{"location":"Kerberos/#overview","text":"Kerberos is an authentication protocol, which means it is a prescribed method for a user to prove their identity to a particular application service over a network. The set of players in the protocol can be seen as: a client program acting on behalf of a user a centralized service, called the Authentication Server (AS) one or more application servers. Kerberos works by using the Authentication Server as a middle-man between clients and applications. The Authentication Server must have a priori knowledge of: all users in the system all application services in the system to allow a user known by the Authentication Server to prove their identity to an application service known by the Authentication Server.","title":"Overview"},{"location":"Kerberos/#what-does-known-by-the-authentication-server-mean","text":"During the system's set-up, the Authentication Server must be informed about all users in the system. This means for each user, an account is created on the Authentication Server and given a password chosen by the user. The username, password, and the Kerberos version number are encrypted using an agreed-upon encryption scheme to produce a secret key for the user. Now, the user can use their username and password under the same encryption scheme to re-create their secret key from anywhere. The user can therefore send confidential messages to the Authentication Server over a network by encrypting the message with their secret key. Similarly, each application service must be issued a secret key that it can use to communicate with the Authentication Server over a network.","title":"What does \"known by the Authentication Server\" mean?"},{"location":"Kerberos/#the-basic-kerberos-protocol","text":"Note: in the diagrams below, colors are used to help clarify which segments are encrypted by which keys, since there are three keys involved, and it can get confusing. When a client wants to prove its identity to an application, it sends a message containing the user's username (in cleartext) and a request to authenticate to a particular application service (encrypted by the user's secret key) to the Authentication Server. The Authentication Server looks up the username to find the user's secret key and uses it to decrypt the request. The Authentication Server then creates a Kerberos ticket containing: a session key the session key expiration time the user's identity. The Authentication Server creates a response containing a cleartext version of the ticket AND a version of the ticket encrypted using the desired application service's secret key. The Authentication Server then encrypts the entire response using the user's shared key and sends it to the client. Now the client sends the application server a request containing: the Kerberos ticket encrypted by the application service's secret key (received from the Authentication Server) an \"authenticator\" encrypted by the session key containing the current time a checksum the user's identity and sends it to the application server. Finally, the application server decrypts the Kerberos ticket using its own secret key, and decrypts the authenticator using the session key from the ticket. The application server calculates the checksum for the request and checks if it matches the checksum in the authenticator. If it does, then the application server knows the same session key was used to encrypt the authenticator as to decrypt it, so the sender must have known the session key in the ticket. The application server then verifies the identity of the sender by checking that the identity in the ticket matches the identity in the authenticator. The client can optionally include a request that the application server also prove its identity. In this case, the application server sends a response encrypted by the session key (thereby proving that the application server was able to decrypt the ticket using its secret key).","title":"The Basic Kerberos Protocol"},{"location":"Kerberos/#single-sign-on-sso-and-ticket-granting-tickets","text":"If the system contains a set of application services which a user should be able to access, it is desirable for the user to be able to authenticate just once rather than once for each service. A simple way to do this is to cache the user's password in memory, but a safer way is to use an extended version of the Kerberos protocol which caches only tickets and encryption keys for a limited time. When the user logs in, an authentication request for the ticket granting service is issued to the Authentication Server. The ticket that is returned is called the ticket granting ticket. The version of the ticket granting ticket encrypted by the ticket granting service's secret key is cached on the client, along with the session key from the ticket granting ticket. Now when the user accesses a new service (and therefore needs to authenticate to that service), a ticket for that service is requested from the Authentication Server via the ticket granting service.","title":"Single Sign-On (SSO) and Ticket Granting Tickets"},{"location":"Kerberos/#using-the-session-key-for-further-communication","text":"As a by-product of the authentication protocol, the client and application server end up with a shared key that they can use to further exchange private encrypted messages.","title":"Using the Session Key for Further Communication"},{"location":"Kerberos/#sources","text":"Draws heavily from USC/ISI Technical Report number ISI/RS-94-399 Redmond Magazine Blog post by Lynn Root","title":"Sources"},{"location":"Kerberos/#further-reading","text":"Current Kerberos release from MIT Red Hat Enterprise Linux 3: Reference Guide, Chapter 18. Kerberos Set up Kerberos on FreeBSD","title":"Further Reading"},{"location":"Kerberos/#related-topics","text":"Public key cryptography and PGP","title":"Related Topics"},{"location":"authentication/","text":"Authentication The following user authentication methods are available for administrative and monitoring purposes: Local SAML RADIUS TACACS+ Note: If you make changes locally and don't reflect them on the SCC, they'll be wiped next time there is a push. Custom Shell profiles and AV pairs are required for SteelHeads. This is covered by many knowledgebase articles. Gist is available for Cisco ACS environments in article 516158 Typically local site admins don't need RW access as everything Should be managed via an SCC .","title":"Authentication"},{"location":"authentication/#authentication","text":"The following user authentication methods are available for administrative and monitoring purposes: Local SAML RADIUS TACACS+ Note: If you make changes locally and don't reflect them on the SCC, they'll be wiped next time there is a push. Custom Shell profiles and AV pairs are required for SteelHeads. This is covered by many knowledgebase articles. Gist is available for Cisco ACS environments in article 516158 Typically local site admins don't need RW access as everything Should be managed via an SCC .","title":"Authentication"},{"location":"best-practice/","text":"SteelHead Best Practices Do not share NICS and use at least 1Gbps Do not use hyperthreading Do not share physical disks between hosts Do not over provision CPU Use a Server Grade CPU for the Hypervisor Allow resources Hypervisor overhead Always reserve Virtual RAM / Physical RAM Use SSDs or other high speed disk for the Segstore Apply BIOS power settings for maximum performance","title":"SteelHead Best Practices"},{"location":"best-practice/#steelhead-best-practices","text":"Do not share NICS and use at least 1Gbps Do not use hyperthreading Do not share physical disks between hosts Do not over provision CPU Use a Server Grade CPU for the Hypervisor Allow resources Hypervisor overhead Always reserve Virtual RAM / Physical RAM Use SSDs or other high speed disk for the Segstore Apply BIOS power settings for maximum performance","title":"SteelHead Best Practices"},{"location":"bonus/","text":"Bonus Material Transcript So a government federal government customer recently was interested in the client accellerator and was pretty much one of the first clients for this service. They didn't have client accelerated prior, but they had steelheads everywhere. So what we've done is raise zero dollar purchase order to give them client accelerator for free. To tap into this, which I recommend everyone does because it's awesome and it's free because you've already bought the products. If you don't have a client accelerator that you'll use separately, then you can use it just for this for free. And if you have steelheads everywhere already, then then you missing out on awesome opportunities. You need v9.1.2 or later and you need control of v6.2 or later so that with new passwords. Anyway we're on v9.1.2 and v6.3.1 at the moment. It can be deployed in this two ways; SSL agent or optimization SSL agent.You'll see the difference os that one's got a steelhead on the client side and the agent is deployed for free and there is no license required. It essentially uses latency detection to do its job and we can stipulate that if it's less than 10 milliseconds, then your behind a steelhead and don't need to optimize anything because it for you. The other story is where you have a standalone terminal or a user that already has the actual client accelerator . We don't go into this a whole lot as I don't believe it is in this course at all. but the way it works (just briefly) is the client accelerator where it works? Is that a license is consumed when the host is online. So, so if you buy a hundred bison to the new, got 300 people, but all 300 online, at the same time and you may get by, with a hundred freedom calls. So it kind of works like that, where if someone is online and connected, they'll take a seat. No consume one of the licenses. And then they'll hand it back from, it's not used because so, there's no requirements for that and on this one and then in this case, where they already are, just, and then user hanging off the back of a standalone kit or something like that, then they'll get the normal optimizations first, and be etc. All of the streamlining functionality done on the agents. Last this. So, what it does is, if it isn't clear yet and this diagram doesn't really help make it more clear because it's pretty intense diagram. What it does, is it generates search on the fly, on the host that are trusted by the host. Because it's generated on the host effectively because I believe what happens is when you install the engage the enemies are agent. A riverbed client accelerator certificate gets installed in your trusted store or something like that as part of the installation, and if that's not the case denoted, assume it would be something through AD or something like that, but I'm pretty sure it is installed out of the box. So what happened is, that's trusted by your browser. And then what happens is, is this, this one will generated on the fly little pass it on. And typically, what what all essentially happens is, trusted connection will happen with all hosts out there because you've got the ability for this to make the certs that this client needs to trust. So it's a bit bit of a mind blowing concept that's opposed but hopefully it's understandable that what you can do is you can optimize anything because you don't need a proxy set here because this is generating each as the Yeah, that's just a little bit extra and it's something that's very powerful because for example, like like you say, now the other day about news.com for, if your punching through a steelhead before you go out to secure internet gateway, then the optimization in your own network, prior to going out to the internet, will actually happen at this point providing the ability to break and inspect anything without needing to go. And fetch certs is huge. And then you can ask yourself or why would this come about if it's all free? And they've done this major featuring implementation, it doesn't make sense. Well, the answer is, it's a pain in the ass at times to get proxy certs and a lot of the time, the network team doesn't have influence on it. Broadly speaking about all organizations. So rather than anything else, what we can do is we can drive it down as far as possible. We can hit it at the source and then we actually don't require to go on big and played for these thirds because it can be done on the agent and the agent will provide capability and then you know yeah I it's more about sticking this and giving legs to the steelhead because and then this is what differentiates I guess the field heads from the other acceleration options are out there. If many are out there, is that this stuff has continually being maintained and continually being kept up with, what's required by the user community. Because if it's getting too hard and there's too many starts out there and we can't open my internet and blah, blah blah. I don't do this and now we can. So anyway just some extra food to thought because it's, it's an awesome feature / capability. And it's not very well used at the moment because no one really knows about it. So further to that talking about setting it up on a steelhead, all you do is take the one box to enable TLS. The TLS played. It's all you got to do so it's it's it's like you take a box on on the client to enable the steelhead to enable it depending on how you've got it set up. Whether it's the whether it's the agent mode or the accelerator, an agent mode, you only need it on the server side steelhead or you don't on both and you only other thing is an impossible optimized all ports on 443 and in that case, it actually does mean all ports. But sorry all also servers on portfolio hosts and in that case, it actually does the trick.","title":"Bonus Material Transcript"},{"location":"bonus/#bonus-material-transcript","text":"So a government federal government customer recently was interested in the client accellerator and was pretty much one of the first clients for this service. They didn't have client accelerated prior, but they had steelheads everywhere. So what we've done is raise zero dollar purchase order to give them client accelerator for free. To tap into this, which I recommend everyone does because it's awesome and it's free because you've already bought the products. If you don't have a client accelerator that you'll use separately, then you can use it just for this for free. And if you have steelheads everywhere already, then then you missing out on awesome opportunities. You need v9.1.2 or later and you need control of v6.2 or later so that with new passwords. Anyway we're on v9.1.2 and v6.3.1 at the moment. It can be deployed in this two ways; SSL agent or optimization SSL agent.You'll see the difference os that one's got a steelhead on the client side and the agent is deployed for free and there is no license required. It essentially uses latency detection to do its job and we can stipulate that if it's less than 10 milliseconds, then your behind a steelhead and don't need to optimize anything because it for you. The other story is where you have a standalone terminal or a user that already has the actual client accelerator . We don't go into this a whole lot as I don't believe it is in this course at all. but the way it works (just briefly) is the client accelerator where it works? Is that a license is consumed when the host is online. So, so if you buy a hundred bison to the new, got 300 people, but all 300 online, at the same time and you may get by, with a hundred freedom calls. So it kind of works like that, where if someone is online and connected, they'll take a seat. No consume one of the licenses. And then they'll hand it back from, it's not used because so, there's no requirements for that and on this one and then in this case, where they already are, just, and then user hanging off the back of a standalone kit or something like that, then they'll get the normal optimizations first, and be etc. All of the streamlining functionality done on the agents. Last this. So, what it does is, if it isn't clear yet and this diagram doesn't really help make it more clear because it's pretty intense diagram. What it does, is it generates search on the fly, on the host that are trusted by the host. Because it's generated on the host effectively because I believe what happens is when you install the engage the enemies are agent. A riverbed client accelerator certificate gets installed in your trusted store or something like that as part of the installation, and if that's not the case denoted, assume it would be something through AD or something like that, but I'm pretty sure it is installed out of the box. So what happened is, that's trusted by your browser. And then what happens is, is this, this one will generated on the fly little pass it on. And typically, what what all essentially happens is, trusted connection will happen with all hosts out there because you've got the ability for this to make the certs that this client needs to trust. So it's a bit bit of a mind blowing concept that's opposed but hopefully it's understandable that what you can do is you can optimize anything because you don't need a proxy set here because this is generating each as the Yeah, that's just a little bit extra and it's something that's very powerful because for example, like like you say, now the other day about news.com for, if your punching through a steelhead before you go out to secure internet gateway, then the optimization in your own network, prior to going out to the internet, will actually happen at this point providing the ability to break and inspect anything without needing to go. And fetch certs is huge. And then you can ask yourself or why would this come about if it's all free? And they've done this major featuring implementation, it doesn't make sense. Well, the answer is, it's a pain in the ass at times to get proxy certs and a lot of the time, the network team doesn't have influence on it. Broadly speaking about all organizations. So rather than anything else, what we can do is we can drive it down as far as possible. We can hit it at the source and then we actually don't require to go on big and played for these thirds because it can be done on the agent and the agent will provide capability and then you know yeah I it's more about sticking this and giving legs to the steelhead because and then this is what differentiates I guess the field heads from the other acceleration options are out there. If many are out there, is that this stuff has continually being maintained and continually being kept up with, what's required by the user community. Because if it's getting too hard and there's too many starts out there and we can't open my internet and blah, blah blah. I don't do this and now we can. So anyway just some extra food to thought because it's, it's an awesome feature / capability. And it's not very well used at the moment because no one really knows about it. So further to that talking about setting it up on a steelhead, all you do is take the one box to enable TLS. The TLS played. It's all you got to do so it's it's it's like you take a box on on the client to enable the steelhead to enable it depending on how you've got it set up. Whether it's the whether it's the agent mode or the accelerator, an agent mode, you only need it on the server side steelhead or you don't on both and you only other thing is an impossible optimized all ports on 443 and in that case, it actually does mean all ports. But sorry all also servers on portfolio hosts and in that case, it actually does the trick.","title":"Bonus Material Transcript"},{"location":"bypass-nic/","text":"SteelHead-V and Riverbed Bypass NIC Riverbed Bypass NIC-A physical card for the virtual device. ESX/ESXI Direct Path feature Allows SteelHead-v to contral the bypass hardware: ESXI driver available from the support website Under related Software Hyper-V & KVM support","title":"SteelHead-V and Riverbed Bypass NIC"},{"location":"bypass-nic/#steelhead-v-and-riverbed-bypass-nic","text":"Riverbed Bypass NIC-A physical card for the virtual device.","title":"SteelHead-V and Riverbed Bypass NIC"},{"location":"bypass-nic/#esxesxi","text":"Direct Path feature Allows SteelHead-v to contral the bypass hardware: ESXI driver available from the support website Under related Software Hyper-V & KVM support","title":"ESX/ESXI"},{"location":"cheetsheet/","text":"Cheetsheet SCP Commands Copy Single Files $ scp user@remote_host.com:/some/remote/directory ~/my_local_file.txt Copy Multiple Files $ scp username@remotehost:/path/directory/ \\{ foo.txt,bar.txt \\} . Verbose Output $ scp -v source_file_path destination_file_path Copy Entire Directory (Recursively) $ scp -r source_file_path destination_file_path Speed Up Transfer with Compression $ scp -C source_file_path destination_file_path Specify Identity File $ scp -i private_key.pem ~/test.txt root@192.168.1.3:/some/path/test.txt","title":"Cheetsheet"},{"location":"cheetsheet/#cheetsheet","text":"","title":"Cheetsheet"},{"location":"cheetsheet/#scp-commands","text":"","title":"SCP Commands"},{"location":"cheetsheet/#copy-single-files","text":"$ scp user@remote_host.com:/some/remote/directory ~/my_local_file.txt","title":"Copy Single Files"},{"location":"cheetsheet/#copy-multiple-files","text":"$ scp username@remotehost:/path/directory/ \\{ foo.txt,bar.txt \\} .","title":"Copy Multiple Files"},{"location":"cheetsheet/#verbose-output","text":"$ scp -v source_file_path destination_file_path","title":"Verbose Output"},{"location":"cheetsheet/#copy-entire-directory-recursively","text":"$ scp -r source_file_path destination_file_path","title":"Copy Entire Directory (Recursively)"},{"location":"cheetsheet/#speed-up-transfer-with-compression","text":"$ scp -C source_file_path destination_file_path","title":"Speed Up Transfer with Compression"},{"location":"cheetsheet/#specify-identity-file","text":"$ scp -i private_key.pem ~/test.txt root@192.168.1.3:/some/path/test.txt","title":"Specify Identity File"},{"location":"deployment-methods/","text":"Deployment Methods Deployment Methods: Physical In-Path LAN & WAN Connected We will look into more detail on: Serial clusters Parallel clusters Simplified Routing Failover Scenarios Deployment Methods: Virtual In-Path WAN physically connected: in-paths interfaces used for optimization We will look into more detail on: Policy-based Routing WCCP Interceptor Layer-4 Switch Deployment Methods: Cloud Optimization Cloud Computing Private cloud Resources match demand, but can be slow or expensive to adapt Management of resources without restrictions Security Compliance High Availability, but at a cost Public cloud Scalable and agile Consumer-based billing High Availability Hybrid cloud As the name implies. Deployment Methods & Network Asymmetry Network Asymmetry Affects Optimization Asymmetric Routing (AR) can be disruptive in optimized environments! SteelHeads need two-way traffic to optimize, regardless of topology: In-path virtual in-path Virtual in-path can also be a solution, more later As a result the initial connection will take longer, or even fail SteelHeads will pass through all IP pairs for 24 hours when AR detected. This is to avoid reoccurring fallures The table can be flushed manually, but must be done on all affected SteelHeads Consider manual reset or an auto-kickoff rule Remember nothing happens until we see a SYN message .","title":"Deployment Methods"},{"location":"deployment-methods/#deployment-methods","text":"","title":"Deployment Methods"},{"location":"deployment-methods/#deployment-methods-physical-in-path","text":"LAN & WAN Connected We will look into more detail on: Serial clusters Parallel clusters Simplified Routing Failover Scenarios","title":"Deployment Methods: Physical In-Path"},{"location":"deployment-methods/#deployment-methods-virtual-in-path","text":"WAN physically connected: in-paths interfaces used for optimization We will look into more detail on: Policy-based Routing WCCP Interceptor Layer-4 Switch","title":"Deployment Methods: Virtual In-Path"},{"location":"deployment-methods/#deployment-methods-cloud-optimization-cloud-computing","text":"","title":"Deployment Methods: Cloud Optimization Cloud Computing"},{"location":"deployment-methods/#private-cloud","text":"Resources match demand, but can be slow or expensive to adapt Management of resources without restrictions Security Compliance High Availability, but at a cost","title":"Private cloud"},{"location":"deployment-methods/#public-cloud","text":"Scalable and agile Consumer-based billing High Availability","title":"Public cloud"},{"location":"deployment-methods/#hybrid-cloud","text":"As the name implies.","title":"Hybrid cloud"},{"location":"deployment-methods/#deployment-methods-network-asymmetry","text":"Network Asymmetry Affects Optimization Asymmetric Routing (AR) can be disruptive in optimized environments! SteelHeads need two-way traffic to optimize, regardless of topology: In-path virtual in-path Virtual in-path can also be a solution, more later As a result the initial connection will take longer, or even fail SteelHeads will pass through all IP pairs for 24 hours when AR detected. This is to avoid reoccurring fallures The table can be flushed manually, but must be done on all affected SteelHeads Consider manual reset or an auto-kickoff rule Remember nothing happens until we see a SYN message .","title":"Deployment Methods &amp; Network Asymmetry"},{"location":"ead/","text":"Enhanced Auto Discovery (EAD) Why Use EAD? Default since RIOS version 5.5.4 Used to find the LAST Steel Head, not the first Useful on double WAN hops Also useful in serial deployments, but peering rules are much better Faster to fail when the server is not available Faster to detect network asymmetry Why Not Use EAD? May need to be disabled in certain SaaS backhaul deployments, or when overcoming egregious WAN latency such as double satellite Wireshark PCAP of EAD traffic Options: (28 bytes), Maximum segment size, No-Operation (NOP) Maximum segment size: 1460 bytes No-Operation (NOP) Window scale: 8 (multiply by 256) No-Operation (NOP), No-Operation (NOP) TCP SACK Permitted Option: Truel Riverbed Probe: Probe Query, CSH IP: 10.1.120.21 Length: 10 Kind: Riverbed Probe (76) Length: 10 0000... Type: 0 .... 0001 Version: 1 Reserved: 0x01 CSH IP: 10.1.120.21 Application Version: 5 Riverbed Probe: Probe Query Info Length: 4 Kind: Riverbed Probe (76) Length: 4 0000 110. Type: 6 .......8 Version: 2 Probe Flags: 0x21 No-Operation (NOP) End of Option List (EOL)","title":"Enhanced Auto Discovery (EAD)"},{"location":"ead/#enhanced-auto-discovery-ead","text":"","title":"Enhanced Auto Discovery (EAD)"},{"location":"ead/#why-use-ead","text":"Default since RIOS version 5.5.4 Used to find the LAST Steel Head, not the first Useful on double WAN hops Also useful in serial deployments, but peering rules are much better Faster to fail when the server is not available Faster to detect network asymmetry","title":"Why Use EAD?"},{"location":"ead/#why-not-use-ead","text":"May need to be disabled in certain SaaS backhaul deployments, or when overcoming egregious WAN latency such as double satellite","title":"Why Not Use EAD?"},{"location":"ead/#wireshark-pcap-of-ead-traffic","text":"Options: (28 bytes), Maximum segment size, No-Operation (NOP) Maximum segment size: 1460 bytes No-Operation (NOP) Window scale: 8 (multiply by 256) No-Operation (NOP), No-Operation (NOP) TCP SACK Permitted Option: Truel Riverbed Probe: Probe Query, CSH IP: 10.1.120.21 Length: 10 Kind: Riverbed Probe (76) Length: 10 0000... Type: 0 .... 0001 Version: 1 Reserved: 0x01 CSH IP: 10.1.120.21 Application Version: 5 Riverbed Probe: Probe Query Info Length: 4 Kind: Riverbed Probe (76) Length: 4 0000 110. Type: 6 .......8 Version: 2 Probe Flags: 0x21 No-Operation (NOP) End of Option List (EOL)","title":"Wireshark PCAP of EAD traffic"},{"location":"housekeeping/","text":"Housekeeping Licensing Structure Licenses are small strings of text tied to the HW Example: LK1-SH40SSL-0000-0000-5-8B40-0361-F11D Basic Licenses plus options and sizing can be added by: CLI GUI Call Home function Export Flow Statistics NetFlow and other Flow Data Collectors gather network statistics about network hosts, protocols and ports, peak usage times, traffic paths, and others The flow data collectors update flow records with information pertaining to each packet traversing a specified network interface Flow Data Component Basics Exporter: A device that sees the data flows going through the network, such as a SteelHead or a router Collector: A server or appliance designed to aggregate data sent to it by NetFlow Exporter, such as Steel Central Flow Gateway Analyzer: A collection of tools (usually provided in conjunction with a collector) used to analyze the data and provide relevant data summaries and graphs, such as SteelCentral NetProfiler Configuration Management The Configuration is held in binary format Pasting a text file to the CLI is NOT recommended Configuration files are backed up locally with a .bak copy and can be uploaded manually to a server: Files are also regularly backed up to the SCC Files can be saved locally before every change Creates an easy rollback if required in a service window","title":"Housekeeping"},{"location":"housekeeping/#housekeeping","text":"","title":"Housekeeping"},{"location":"housekeeping/#licensing-structure","text":"Licenses are small strings of text tied to the HW Example: LK1-SH40SSL-0000-0000-5-8B40-0361-F11D Basic Licenses plus options and sizing can be added by: CLI GUI Call Home function","title":"Licensing Structure"},{"location":"housekeeping/#export-flow-statistics","text":"NetFlow and other Flow Data Collectors gather network statistics about network hosts, protocols and ports, peak usage times, traffic paths, and others The flow data collectors update flow records with information pertaining to each packet traversing a specified network interface","title":"Export Flow Statistics"},{"location":"housekeeping/#flow-data-component-basics","text":"Exporter: A device that sees the data flows going through the network, such as a SteelHead or a router Collector: A server or appliance designed to aggregate data sent to it by NetFlow Exporter, such as Steel Central Flow Gateway Analyzer: A collection of tools (usually provided in conjunction with a collector) used to analyze the data and provide relevant data summaries and graphs, such as SteelCentral NetProfiler","title":"Flow Data Component Basics"},{"location":"housekeeping/#configuration-management","text":"The Configuration is held in binary format Pasting a text file to the CLI is NOT recommended Configuration files are backed up locally with a .bak copy and can be uploaded manually to a server: Files are also regularly backed up to the SCC Files can be saved locally before every change Creates an easy rollback if required in a service window","title":"Configuration Management"},{"location":"lab-1/","text":"HOL1131: Optimization with Windows file share (SMB) Demo Introduction This exercise introduces the user interface and effectiveness of WAN optimization using Riverbed Optimization System, RiOS. Overview In this exercise you will monitor and record transfer times of traffic you generate to witness optimization efficacy. This eLab is designed for you to gain working knowledge of some basic SteelHead concepts and optimization effects, and presumes little to no familiarity with the SteelHead UI. The network environment has two sites: Host SteelHead City Site Branch Office n21-win10 n120-sh1 San Francisco, California Site A Datacenter n31-svr n130-sh1 Ashburn, Virginia Site B These sites are connected by a WAN with approximately 70ms latency, 1.5Mbit/sec, and 0.5% loss . The SteelHead virtual appliances in this scenario are pre-configured, to allow your focus to be on the effects of optimization and benefits to user experience. More information on topics covered in this exercise can be found here: SteelHead CX Installation and Configuration Guide Chapter 3, Installing and Configuring the SteelHead Chapter 4, Troubleshooting SteelHead Deployment Guide Chapter 3, WAN Visibility Modes Chapter 9, Physical In-Path Deployments SteelHead Deployment Guide - Protocols Chapter 1, CIFS Optimization Chapter 3, Signed SMB and Encrypted MAPI Optimization Lab Objectives Map a Network Drive and Experience Non-optimized Environment Allow optimization using in-path rules Create optimized transfers and verify them Create reports on the effects of optimization Task 1. Map a Network Drive and Experience Non-optimized Environment Map a network drive from your Windows Client PC to a Windows file share on the server in the datacenter, then select a file and time how long it takes to copy across the WAN. Due to SMB/Kerberos requirements, we will spend most of this exercise leveraging Remote Desktop Protocol, RDP, into a domain-joined Windows 10 PC, n21-win10 . Recall the SteelHeads have been pre-configured, and for this task the optimization capability - which normally is automatically enabled - has been disabled. You will be re-enabling optimization in the next task. From the taskbar, launch RDP (the icon looking like a computer screen) to make a connection to n21-win10 , using credentials LAB\\elabstudent and myeLab! This places you as a user in the domain lab.local On the n21-win10 client PC, open the File Explorer, click on This PC and select the Computer tab at the top of the window. From the Map Network Drive pop-up window, map the Network drive \\\\share.lab.local\\public As the directory names suggest, there are many file types available, but for now navigate to the Presentations folder and select a file larger than roughly 10MB. We will use the file BoogieWoogieBugleBoy.ppt for our example. It does not matter which file you select, but make a note of yours so you can repeat the same transfer later in a like-for-like comparison with optimization. With a stopwatch ready (your watch or phone or the Clock widget at lower-right of the n21-win10 desktop would work) copy the file and make note of how long the transfer takes. Once the copy is completed and you've noted the transfer time, let's see how the SteelHead reports on this connection. Start Firefox and use the provided shortcut, Site A - Branch > Optimization > n120-sh1 SteelHead (Path 1) , to access n120-sh1 ; logon with credentials admin :: password . On the n120-sh1 UI, navigate to Reports > Networking: Current Connections You should see a connection with: \"Destination:Port\" = 10.1.31.120:445 \"Connection Type\" = grey arrow (which the legend shows us is an \"Intentional\" pass-through) \"Passthrough reason\" = In-path rule To see details of the connection you press the gray \"Show details\" triangle on the left. The \"Passthrough reason: In-path rule\" tells us this client-side SteelHead is passing the connection through because it has been administratively informed to do so. That's the purpose of an in-path rule: Us telling the SteelHead whether it should attempt to optimize (or not, as in this case), and if so, how to do so. Still on n120-sh1 , head to Reports > Networking: WAN Throughput Click on the 5m Time Selector (or \"1h\" if it's been longer than 5 minutes since you copied the file over) to 'zoom in' to the best resolution view of your transfer Note the x-axis of the graph provides an indication of how long your transfer took. This works splendid in our Lab, with only our one connection to view, but on a SteelHead carrying production traffic with hundreds or thousands of optimized connections, isolating a single transfer on this report is not possible. Now that you've experienced an unoptimized transfer, and been informed why it is not being optimized, return to the File Manager app, right click on the \\\\n31-svr\\public shared drive and disconnect it. Worthy of Note: We disconnect the drive now because SteelHeads do not start optimizing existing/pre-existing connections. A SteelHead will not attempt to initiate optimization of connections it has not seen the SYN message for; will simply pass them through. After we re-enable optimization on the SteelHead, we will re-map the drive so the SteelHead can see the very beginning of the connection and attempt to optimize it. In other words, SteelHeads identify the SYN packet of each connection to evaluate if optimization should occur, or if the SYN packet - and all subsequent packets for the connection - should be passed through without optimization. Having a baseline of 'performance without optimization', we can compare this to the transfer time of subsequent optimized transfers. Task 2. Allow optimization using in-path rules You will first 're-enable' optimization on the branch SteelHead, n120-sh1 by adjusting the in-path rules. On n120-sh1 , navigate to > Optimization > Network Services: In-Path Rules . SCAN the in-path rules to see at a high level what they do: Identified Columns: Type = \"Pass Through\" or \"Auto Discover\" Source & Destination = IP Addresses on the SYN Packet being evaluated for optimization. Rule # = Hierarchic order; rules evaluated top to bottom like access control list (ACL). One Rule to note is \"default\", whose purpose is to attempt to optimize, via auto-discovery, any new TCP connection not passed through by above rules. This \"default\" rule cannot be deleted, effectively causing SteelHeads to behave in a \"blacklist\" manner, where every TCP connection has optimization attempted except those explicitly passed through, or blacklisted, via previously evaluated in-path rules. To re-configure this SteelHead to attempt optimization, you are welcome to either: Disable the rule by clicking on the twisty next to the rule number, scroll down and uncheck Enable Rule , and click Apply , or Delete this first rule by ticking it's checkbox on the far left and clicking Remove Selected Rules Your SteelHead will now attempt to optimize all LAN-to-WAN TCP traffic not matching the remaining, default pass-through rules. Task 3. Create optimized connections and verify them. You will now re-map the network drive as you did in Task 1. This time however, the SteelHeads will create an optimized session using, as you may have noticed in the bottom-most default in-path Rule, Auto Discovery. You will then verify optimization status. Re-map the network drive \\\\share.lab.local\\public on n21-win10 In the File Explorer window, select This PC and the Computer tab at the top, and either re-type the URL or use the drop-down, which should have the address cached. Now, on n120-sh1 GUI, return to Reports > Networking: Current Connections to see the connection in an optimized state. Should your connection not be optimized... this is a perfect opportunity to review the above and your course material to determine why! In a live environment you may well see tens of thousands of connections or more, so take a moment to review your options for filtering on this page. Note also, on your optimized connection you should see the version of SMB currently in use, and the Username , which is populated from the Active Directory integration. Knowledge check: In the view below, what informs the connection is optimized? In the view below, what informs the connection is encrypted over the WAN? Hint: hovering icons in your Current Connections screen can answer both questions... Knowing your connection is optimized, and with your stopwatch at the ready, use File Manager to repeat the transfer of the same file you used before, and time how long it takes. Since the byte patterns of this file is being seen/optimized for the first time by these two SteelHeads, this is a \u201ccold\u201d transfer. Whether the end user notices a significant speed improvement or not, the data segments are being segmented/'learned' by both SteelHeads and stored to allow future \u201cwarm\u201d transfers when the same patterns are passed between these two SteelHeads again. During the file transfer, on the File Manager transfer pop-up you can expand the caret in the bottom left corner to view more details. With transfer finished, compare this \"cold\" transfer time with the \"unoptimized\" transfer time. Keep in mind that bandwidth reduction benefits are more tangible to Users over slower or oversubscribed WAN links. It is latency reduction which Users feel the most, which SteelHeads usually impact most with their Application-layer optimization. However, less bandwidth used is also a perspective; for instance: Tell a User they consumed 60% less bandwidth and they'll say \"So what.\" Tell a Network Admin or CFO their data circuits are 60% less utilized, and they'll say \"Amazing!\" Let's move on to the \"warm\" transfer... start by deleting the local copy of your file on n21-win10 , then raise your stopwatch and repeat the transfer once more - but you will have to be quick! Calculate the approximate speed for the SMB file transfers, cold and warm. How do they compare to the previous non optimized transfer? Take some time to experiment Try changing a PowerPoint document and saving it as another file, then passing it back to the server. Try doing the same with different file types. For instance, Drag 'n drop the whole Databases folder (which contains ~3Mb of database files) to the n21-win10 - Downloads folder. Pause a few moments, then go into the \\\\share.lab.local\\public\\High-Res Images folder and copy \"wallpaper-1985738.png\" (also roughly 3Mb, but one file), On n130-sh1 navigate to Reports > Optimization > Optimized Throughput and compare the LAN and WAN impact of those two transfers. You should be able to discern the 3Mb of database traffic impacted the WAN & LAN less, and perhaps even took a bit less time, than the 3Mb picture file. Knowledge Check: Why would the optimization effects differ on a \"cold pass\" of one type of data/traffic versus another? We can now use the SCC in the data center to generate some HTTP traffic. Open a tab in Firefox and browse to http://10.1.31.50 and logon with admin and password . Click around the menus just to generate traffic. Then, open another tab and navigate to https://10.1.31.50 . (accept the security risk in this Lab environment) On n120-sh1 , view the Current Connection details to compare the two connections to n31-scc . Both access techniques can be optimized, but in this case SSL optimization is not configured so, per default behavior, tcp/443 traffic will be passed through; HTTP is optimized by default. For an advanced concept, navigate to the Current Connections page of n130-sh1 and compare the pass-through reason for the tcp/443 connection. This may help highlight the perspective a server-side SteelHead has on connections, versus a client-side SteelHead. Task 4. Create reports on the effects of optimization You will view reports showing WAN traffic reduction aspects of your previous transfers. You can also: Check on the SteelHead's peer table and look at the DataStore status, View the LAN throughput, a most important statistic as this is where the user experience lies. LAN throughput increase is due to a combination of WAN data reduction (usually to a lesser degree), and TCP & Application layer RTT optimizations (often the major contributor). Let's check out the server-side SteelHead perspective. Create a new browser tab if necessary to open the n130-sh1 GUI, and navigate to Reports > Networking > Traffic Summary Notice the filtering defaults of Period: 1 Month and Traffic: Optimized traffic . Change them to 5 minutes (or \"Last Hour\" if necessary) and Both , respectively What percentage of the total traffic was optimized? What percentage of that traversed the WAN? Also notice you can sort your metric of choice by clicking on the respective column header; helps quickly identify outliers of interest. In many cases we are more interested in what is not going so well; for instance when you see a port with substantial amounts of optimized traffic yet with no reduction, that port is likely to be carrying encrypted traffic. Your choices in this specific case include: a) Identify the traffic and either decrypt it somehow, or switch off encryption. (obviously requires dialog with the application owner) b) Pass it through, if decryption/non-encryption is not an option and TCP optimizations are not a tangible timesaver (would require testing to validate). It may be better to pass through that which cannot be optimized, to preserve resource for that which can. And if we cannot make it slimmer and/or faster, we can easily pass it through. (a consideration for substantial-throughput connections; usually a non-issue for smaller connections) Now view the Reports > Optimization > Optimized Throughput report. Notice in the Controls panel on the right-hand side your Time Selection options, which include typing into the time field, choosing one of the presets, or using the time control scroller bar at the bottom of the chart. Notice also, below the Time selection area, that this report allows you to choose a single port of interest or All, and you can view or omit the LAN, WAN, Peaks and Averages chart presentations by unchecking them. What was the peak LAN throughput in your timescale for HTTPS traffic? What was it for HTTP and SMB? It should be noted that for optimized traffic originating on port 445, SteelHead reporting refers uniquely to the different SMB versions, options and dialects. For example, SteelHeads report on SMB3-signed traffic as port 8782. The \"real\" port number on the connections (as Hosts on the outer channels see it) remains 445. The Current Connections report shows which connection is using which SMB type, and Filtering allows isolating to a particular protocol if desired. Run a report on Reports > Optimization > Bandwidth Optimization Note the scale on the Y axis of the chart is automatically adjusted to suit. Hover the mouse over the plot area to display the Data Reduction for various points on the timeline. Note that the LAN Throughput should be greater than WAN Throughput to imply optimization occurring and reducing the amount of throughput on the WAN. What was the peak LAN throughput? When did it happen? What protocol was it? What was the total amount of data that was removed from the WAN during your time period? Run a report on Reports > Optimization > Data Store Status Note the percentage of the data store have you used. What will happen when it becomes 100% full? End of Scenario You have successfully created optimized traffic in an in-path deployment, and should understand the nature of cold and warm file transfers. Ideally you noticed significant improvement in transfer times, even with file modifications. Useful add-on: SDR is protocol agnostic, so the warm transfer of a byte stream in one application will be equally optimized should that byte stream occur in a different applications. As an example, downloading a file from the datacenter via a file share, then sending the file via email; your local and datacenter SteelHeads will see the file 'cold' when downloading, then 'warm' when that same file is attached to an email. Finally, you verified various optimization statistics in different Reports. Good to note that bandwidth reduction/optimization is enabled by default for all TCP ports not explicitly passed through. Once your SteelHead appliance is plugged in and configured with the initial network settings, you can begin optimizing traffic and notice significant performance increase, with accompanying WAN data reduction.","title":"Lab 1"},{"location":"lab-2/","text":"HOL5923: Create Web App Dashboards Introduction Overview In this lab scenario, you are part of the End-User Services team currently using SteelCentral AppResponse and Portal to monitor the performance of your company\u2019s public facing website. You are now tasked by management to create and share dashboards that display the website\u2019s usage and performance. The new dashboards are to be shared with two user groups, management and the help desk staff on the tier 1 support team. Lab Objectives Review the Advanced Web Applications and Host Groups That Have Been Defined on AppResponse to Monitor the Public Website Create an SLA Dashboard in SteelCentral Portal to Monitor the Website\u2019s Most Important Pages and User Locations to be Shared with Management Create a Web Application Performance Dashboard That Monitors the Public Website and That Can be Used by the Helpdesk as Starting Point to Perform Triage and Troubleshooting in the Event of Poor Performance Task 1. Review the Advanced Web Applications and Host Groups that have been defined on AppResponse to monitor the public website. Objective In this task, you will browse the data source, AppResponse to observe how it is currently configured to monitor the public website. Detailed Steps Access the AppResponse user interface at https://10.99.31.240 or using the browser bookmark DataCenter Hosts > n31-arx SC AppResponse . If necessary, add the security exception to accept the use of the self-signed certificate. Login using the credentials admin/admin . It may take a few minutes for the Time to synchronize. Navigate to DEFINITIONS > Applications to observe the list of applications currently defined on the AppResponse appliance. Click on the Web tab to view the application definitions used by the AppResponse Web Transaction Analysis Module. Use the information on this page to answer the following questions: How many Web Application definitions are supported on this appliance? How many Web Application definitions have already been defined? What is the Traffic Matching Mode of all of these application definitions? How many of these application definitions are related to the PUBLIC WEBSITE? Click on the Edit button (the Pencil to the right)in the row for the PUBLIC WEBSITE definition (the one with no additional \"Description\") to view the URL and any additional parameters used to define this app. Compare this definition to the definitions used for other PUBLIC WEBSITE pages. Use the information from these definitions to answer the following questions: How long would a page load have to take to complete to be considered a slow page by these definitions? Do the application definitions contain overlapping URL patterns? Which of the application definitions is the most specific? Close the Edit Web Application dialog box. Navigate to DEFINITIONS > Host Groups to observe the list of host groups currently defined on the AppResponse appliance. Sort the Host Group Configuration table by Status by clicking on the descending arrow in the appropriate column header. Use this Host Group table to answer the following questions: How many Host Groups are enabled? How many Host Groups represent office locations? Are there any Host Groups that are enabled but not an office location? You may have to wait 5 minutes for the Host Groups and New Applications to accumulate data. Go to Home Click on recent 1 Hour in the upper right corner. Navigate to INSIGHTS > Web > Web App . Enter PUBLIC WEBSITE as your input. Click Launch to open the Insight. Use the information displayed in the Insight to answer the following questions: How many times was the page viewed in the last hour? What is the average page time for the PUBLIC WEBSITE? Which Web User Group experienced the worst page time? When did the worst page time occur? What page family delivered the worst page time? Task 2. Create an SLA Dashboard in SteelCentral Portal to monitor the website\u2019s most important pages and user locations to be shared with management. Objective In this task, you will add the AppResponse appliance as a data source for Portal and create dashboards based on packet inspection metrics for the public website. Detailed Steps Access the Portal user interface at https://10.99.31.200 or using the browser bookmark DataCenter Hosts > n31-prtl SC Portal . If necessary, add the security exception to accept the use of the self-signed certificate. Login using the credentials admin/admin . After logging in, you will be prompted to add a data source to Portal. Select Yes to continue and complete the process of adding the data source with the information listed below: Data source type: AppResponse Hostname: 10.99.31.240 Port: 443 Description: eLab AppResponse Username: admin Password: admin Click Connect to proceed. The process will take 1-2 minutes to complete and the final result should be Connected Successfully . Navigate to DASHBOARDS > Create . In the resulting Create a New Dashboard wizard, scroll down select the SLA Dashboard by Page Time (AppResponse) and click Next to continue. On the Select Web User Groups step, select all of the Office locations and Default- Internet Group and click Next to continue. On the Select Web Applications step, select all of the PUBLIC WEBSITE applications and click Next to continue. On the Select Data Sources step, select Use all connected data sources and click Next to continue. On the Set dashboard options step, change the Dashboard Name to Public Website SLA Dashboard , leave the Dashboard Size as current browser size and click Create . Congratulations, you have now created your first Portal dashboard. This is a high level SLA Dashboard that is suitable for management and line-of-business owners to monitor the status of application performance from each location without configuring or navigating the underlying AppResponse data source. Ideally each LED on this dashboard would show a page time within acceptable limits represented by the green check-mark. Explore the Drilldown options available from the LEDs on the SLA Dashboard. On a single LED that is in the critical state (red X), right-click > Drilldowns > Web Application Details . Use the resulting Dashboard to answer the following questions: Which Web User Group experienced the worst page time? For this group, which component of delay was the highest contributor to page time? Hint: Hover over bar chart components for numerical values. Return to your SLA dashboard by navigating to DASHBOARDS > RECENTS > Public Website SLA . Find and use the drilldown option that allows you to view the performance of all web applications for a specific site, Great Lakes Office . What is the web app with the highest throughput at this site? What is the web app with the highest number of slow pages at this site? How many Slow Pages for the public website were experienced at this site? Task 3. Create a web application performance dashboard that monitors the public website and that can be used by the helpdesk as a starting point to perform triage and troubleshooting in the event of poor performance. Objective In this task, you will design your dashboards to meet the needs of two specific groups in your enterprise, IT management and the help- desk. Detailed Steps Navigate to DASHBOARDS > Create . In the resulting Create New Dashboard wizard, scroll down select the Web Application Details dashboard template and click Next to continue. On the Select a Web Application Step, start by typing PUBLIC WEBSITE in the search box and select PUBLIC WEBSITE from the drop down menu when available. On the Select Data Sources step, select Use all connected data sources and click Finish to continue. Click Create to complete the dashboard. Use the dashboard to answer the following questions: Which Page Family delivered the worst page time? Were there any 5xx Server errors observed for this web app? What were the server IP addresses observed for this app? Drilldown into Page Views to identify the busiest servers and clients. Find the PUBLIC WEBSITE Usage panel. On Page Views sparkline, right-click > Drilldowns > Top Server IPs . Repeat the steps above to identify the Top Client IPs. Use the resulting pop-up panels to find: What Client IP had the most page views? How many page views were served by the Top Server? Close the pop-up panels. Drilldown into the slowest Page Family to create a Page Family Details dashboard. On the slowest page family, right-click > Drilldowns > Page Family Details . Use the new dashboard to identify: The slowest client. The slowest server. The slowest user group. Challenge Objective In this challenge, you will find the problematic web page objects on the single slowest public website page view from the Great Lakes office starting in Portal and filtering down to AppResponse individual page views. Hints Return to your Public Website: Web Application Details dashboard. Launch into Summary: Page Views from the Great Lakes Office Web User Group . Use the resulting AppResponse Insight to answer the following questions: How would you describe what the True Plot panel shows? How many unique users accessed the website from this location? What was the page time of the slowest page? What was the slowest object on the page? Was the object slow due to request, response or server time? Challenge 2 In this challenge, you will create an SLA dashboard for monitoring MS Office application performance by location in SteelCentral Portal using only Aternity Activity Scores. Navigate to Administration > Data Sources > Add . Add the LMS SaaS instance of Aternity as a data source for Portal using the following: Hostname: lms-datasource.aternity.com Port: 443 Username: SCAternityPortal_2 Password: 2_163a23b94c8_HlxteFyM72tsiYjJMhbHnNqjP6m6ek Use the Create Dashboard wizard to find and use the appropriate template for an Aternity SLA dashboard. Follow the steps in the wizard to create a dashboard for all Office Locations and all MS Office apps. Use the resulting dashboard to answer the following: What drilldown options are available from this SLA dashboard? What is the only option to navigate from this Portal dashboard to an Aternity Dashboard? End of Scenario This lab exercise demonstrated the use of two different types of dashboards in SteelCentral Portal. The type of dashboard you choose to create depends on the definitions and metrics available from your data sources and the specific requirements of the consumers of dashboard. You first reviewed the existing configuration of app definitions and host groups on the AppResponse appliance before adding it as a data source to Portal. Next, you created two new dashboards and explored a few of the available drilldown options for creating additional dashboards and pop-up panels on demand.","title":"HOL5923: Create Web App Dashboards"},{"location":"lab-2/#hol5923-create-web-app-dashboards","text":"","title":"HOL5923: Create Web App Dashboards"},{"location":"lab-2/#introduction","text":"","title":"Introduction"},{"location":"lab-2/#overview","text":"In this lab scenario, you are part of the End-User Services team currently using SteelCentral AppResponse and Portal to monitor the performance of your company\u2019s public facing website. You are now tasked by management to create and share dashboards that display the website\u2019s usage and performance. The new dashboards are to be shared with two user groups, management and the help desk staff on the tier 1 support team.","title":"Overview"},{"location":"lab-2/#lab-objectives","text":"Review the Advanced Web Applications and Host Groups That Have Been Defined on AppResponse to Monitor the Public Website Create an SLA Dashboard in SteelCentral Portal to Monitor the Website\u2019s Most Important Pages and User Locations to be Shared with Management Create a Web Application Performance Dashboard That Monitors the Public Website and That Can be Used by the Helpdesk as Starting Point to Perform Triage and Troubleshooting in the Event of Poor Performance","title":"Lab Objectives"},{"location":"lab-2/#objective","text":"In this task, you will browse the data source, AppResponse to observe how it is currently configured to monitor the public website.","title":"Objective"},{"location":"lab-2/#detailed-steps","text":"Access the AppResponse user interface at https://10.99.31.240 or using the browser bookmark DataCenter Hosts > n31-arx SC AppResponse . If necessary, add the security exception to accept the use of the self-signed certificate. Login using the credentials admin/admin . It may take a few minutes for the Time to synchronize. Navigate to DEFINITIONS > Applications to observe the list of applications currently defined on the AppResponse appliance. Click on the Web tab to view the application definitions used by the AppResponse Web Transaction Analysis Module. Use the information on this page to answer the following questions: How many Web Application definitions are supported on this appliance? How many Web Application definitions have already been defined? What is the Traffic Matching Mode of all of these application definitions? How many of these application definitions are related to the PUBLIC WEBSITE? Click on the Edit button (the Pencil to the right)in the row for the PUBLIC WEBSITE definition (the one with no additional \"Description\") to view the URL and any additional parameters used to define this app. Compare this definition to the definitions used for other PUBLIC WEBSITE pages. Use the information from these definitions to answer the following questions: How long would a page load have to take to complete to be considered a slow page by these definitions? Do the application definitions contain overlapping URL patterns? Which of the application definitions is the most specific? Close the Edit Web Application dialog box. Navigate to DEFINITIONS > Host Groups to observe the list of host groups currently defined on the AppResponse appliance. Sort the Host Group Configuration table by Status by clicking on the descending arrow in the appropriate column header. Use this Host Group table to answer the following questions: How many Host Groups are enabled? How many Host Groups represent office locations? Are there any Host Groups that are enabled but not an office location? You may have to wait 5 minutes for the Host Groups and New Applications to accumulate data. Go to Home Click on recent 1 Hour in the upper right corner. Navigate to INSIGHTS > Web > Web App . Enter PUBLIC WEBSITE as your input. Click Launch to open the Insight. Use the information displayed in the Insight to answer the following questions: How many times was the page viewed in the last hour? What is the average page time for the PUBLIC WEBSITE? Which Web User Group experienced the worst page time? When did the worst page time occur? What page family delivered the worst page time?","title":"Detailed Steps"},{"location":"lab-2/#objective_1","text":"In this task, you will add the AppResponse appliance as a data source for Portal and create dashboards based on packet inspection metrics for the public website.","title":"Objective"},{"location":"lab-2/#detailed-steps_1","text":"Access the Portal user interface at https://10.99.31.200 or using the browser bookmark DataCenter Hosts > n31-prtl SC Portal . If necessary, add the security exception to accept the use of the self-signed certificate. Login using the credentials admin/admin . After logging in, you will be prompted to add a data source to Portal. Select Yes to continue and complete the process of adding the data source with the information listed below: Data source type: AppResponse Hostname: 10.99.31.240 Port: 443 Description: eLab AppResponse Username: admin Password: admin Click Connect to proceed. The process will take 1-2 minutes to complete and the final result should be Connected Successfully . Navigate to DASHBOARDS > Create . In the resulting Create a New Dashboard wizard, scroll down select the SLA Dashboard by Page Time (AppResponse) and click Next to continue. On the Select Web User Groups step, select all of the Office locations and Default- Internet Group and click Next to continue. On the Select Web Applications step, select all of the PUBLIC WEBSITE applications and click Next to continue. On the Select Data Sources step, select Use all connected data sources and click Next to continue. On the Set dashboard options step, change the Dashboard Name to Public Website SLA Dashboard , leave the Dashboard Size as current browser size and click Create . Congratulations, you have now created your first Portal dashboard. This is a high level SLA Dashboard that is suitable for management and line-of-business owners to monitor the status of application performance from each location without configuring or navigating the underlying AppResponse data source. Ideally each LED on this dashboard would show a page time within acceptable limits represented by the green check-mark. Explore the Drilldown options available from the LEDs on the SLA Dashboard. On a single LED that is in the critical state (red X), right-click > Drilldowns > Web Application Details . Use the resulting Dashboard to answer the following questions: Which Web User Group experienced the worst page time? For this group, which component of delay was the highest contributor to page time? Hint: Hover over bar chart components for numerical values. Return to your SLA dashboard by navigating to DASHBOARDS > RECENTS > Public Website SLA . Find and use the drilldown option that allows you to view the performance of all web applications for a specific site, Great Lakes Office . What is the web app with the highest throughput at this site? What is the web app with the highest number of slow pages at this site? How many Slow Pages for the public website were experienced at this site?","title":"Detailed Steps"},{"location":"lab-2/#objective_2","text":"In this task, you will design your dashboards to meet the needs of two specific groups in your enterprise, IT management and the help- desk.","title":"Objective"},{"location":"lab-2/#detailed-steps_2","text":"Navigate to DASHBOARDS > Create . In the resulting Create New Dashboard wizard, scroll down select the Web Application Details dashboard template and click Next to continue. On the Select a Web Application Step, start by typing PUBLIC WEBSITE in the search box and select PUBLIC WEBSITE from the drop down menu when available. On the Select Data Sources step, select Use all connected data sources and click Finish to continue. Click Create to complete the dashboard. Use the dashboard to answer the following questions: Which Page Family delivered the worst page time? Were there any 5xx Server errors observed for this web app? What were the server IP addresses observed for this app? Drilldown into Page Views to identify the busiest servers and clients. Find the PUBLIC WEBSITE Usage panel. On Page Views sparkline, right-click > Drilldowns > Top Server IPs . Repeat the steps above to identify the Top Client IPs. Use the resulting pop-up panels to find: What Client IP had the most page views? How many page views were served by the Top Server? Close the pop-up panels. Drilldown into the slowest Page Family to create a Page Family Details dashboard. On the slowest page family, right-click > Drilldowns > Page Family Details . Use the new dashboard to identify: The slowest client. The slowest server. The slowest user group.","title":"Detailed Steps"},{"location":"lab-2/#objective_3","text":"In this challenge, you will find the problematic web page objects on the single slowest public website page view from the Great Lakes office starting in Portal and filtering down to AppResponse individual page views.","title":"Objective"},{"location":"lab-2/#hints","text":"Return to your Public Website: Web Application Details dashboard. Launch into Summary: Page Views from the Great Lakes Office Web User Group . Use the resulting AppResponse Insight to answer the following questions: How would you describe what the True Plot panel shows? How many unique users accessed the website from this location? What was the page time of the slowest page? What was the slowest object on the page? Was the object slow due to request, response or server time?","title":"Hints"},{"location":"lab-2/#challenge-2","text":"In this challenge, you will create an SLA dashboard for monitoring MS Office application performance by location in SteelCentral Portal using only Aternity Activity Scores. Navigate to Administration > Data Sources > Add . Add the LMS SaaS instance of Aternity as a data source for Portal using the following: Hostname: lms-datasource.aternity.com Port: 443 Username: SCAternityPortal_2 Password: 2_163a23b94c8_HlxteFyM72tsiYjJMhbHnNqjP6m6ek Use the Create Dashboard wizard to find and use the appropriate template for an Aternity SLA dashboard. Follow the steps in the wizard to create a dashboard for all Office Locations and all MS Office apps. Use the resulting dashboard to answer the following: What drilldown options are available from this SLA dashboard? What is the only option to navigate from this Portal dashboard to an Aternity Dashboard?","title":"Challenge 2"},{"location":"lab-3/","text":"HOL1192: Analyzing Auto Discovery Packets Introduction In this scenario, you will be using Wireshark to analyze TCP dump captures created by the SteelHead appliance to observe the Enhanced Auto Discovery (EAD) process. In upcoming tasks, you will be establishing a new TCP connection to the shared server, initiating the Enhanced Auto Discovery (EAD) process. Background Information TCP Dump is a free and open source packet capture tool that runs from both the SteelHead CLI and the Management Console. It allows network administrators to intercept (capture) TCP/IP and other packets being transmitted or received over networks. TCP Dump was originally written in 1987 by Van Jacobson, Craig Leres and Steven McCanne who were, at the time, working in the Lawrence Berkeley Laboratory Network Research Group. Steven McCanne, Ph.D., went on to co-found Riverbed Technology in May 2002 and served as Riverbed's first CTO. TCP Dump is commonly used in conjunction with Wireshark to analyze network behavior, performance and applications that generate or receive network traffic. TCP Dump is also useful for analyzing network routing infrastructure and providing crucial traffic flow visibility, allowing network engineers to isolate and resolve complex problems. Wireshark (originally named Ethereal ) is a free and open-source packet capture and analyzer tool and is used for network troubleshooting, analysis, software and communications protocol development, and education. In the late 1990s, Gerald Combs, a computer science graduate of the University of Missouri\u2013Kansas City, began writing Ethereal and released the first version around 1998. Combs, in 2006, accepted a job with CACE Technologies to continue development of the product, and subsequently changed its name from Ethereal to Wireshark . In 2010, Riverbed Technology acquired CACE and took over as the primary sponsor of Wireshark. Gerald Combs is the Director of Open Source Projects at Riverbed and lead developer in the Wireshark development team. Tasks Configure TCP Dump on SteelHead Appliance Generate Traffic to Capture Enhanced Auto Discovery (EAD) Probes Download TCP Dump Capture Files from the SteelHead Use Wireshark to Analyze TCP Dump Capture File Change Inner Channel Transparency Mode to Full Transparency Configure and Start a New TCP Dump Use Wireshark to Analyze the New Capture File Task 1. Configure TCP Dump on SteelHead Appliance Objective In this task, you will be creating a new TCP Dump capture job on the branch SteelHead appliance, n120-sh1 . The captured traffic will contain packets that have traversed through the lan0_0 and wan0_0 interfaces on the SteelHead appliance, allowing us to identify the SteelHead auto discovery probe that will appear in the wan0_0 capture file. Detailed Steps Using your Windows client, n21-pc , open Mozilla Firefox or Chrome from the Taskbar shortcut. In the bookmarks toolbar, expand the Branch Optimization folder and select the n120-sh1 SteelHead 1 (Path 1) SteelHead appliance. Login using the following credentials: username: admin password: password Using the branch SteelHead Web UI, navigate to Reports > Diagnostics > TCP Dumps . Click the Add a New TCP Dump button and specify the following capture criteria. Leave any unlisted fields at the default value, and do not click the \"Add\" button until instructed in the upcoming task. This is a time sensitive task that requires additional configuration in the next task. Capture Name: EADprobes In-Path Interfaces: lan0_0 (Check) wan0_0 (Check) Capture Duration: 60 Seconds Leave the browser window open. Review Task 2. Generate Traffic to Capture EAD Probes Objective In this task, you will initiate new TCP connections from your Windows desktop to the HTTP web server. It is important to follow the instructions carefully since this is a time sensitive task. By establishing an HTTP connection, you will initiate the Enhanced Auto-Discovery (EAD) process, which will insert probes into the TCP options field that will be captured by the TCP Dump process staged in the previous task. Detailed Steps Ensure the TCP Dump Configuration task has been completed before proceeding with this task. You will also need to be pretty quick (within 60 seconds between steps 1 and 3) In the SteelHead Web UI TCP Dump capture, click the Add button. EADprobes should appear under TCP Dumps Currently Running Open a new tab in your browser. Using the browser bookmarks toolbar, open Datacenter Hosts > n31-fil File Server (HTTP) in the new tab. http://10.1.31.130 The page will load with a web directory listing of the /public/ directory of your datacenter file server. Return to the SteelHead Web UI browser window. Click the Stop Selected Captures button or simply wait for 60 seconds for the TCP dump to complete. Leave your browser window open. Review By performing a directory listing of the HTTP /public/ directory, you generated a TCP 3-way handshake that subsequently initiated the EAD process. The probes generated in the EAD process were captured by TCP dump process you created and will be analyzed in the next tasks using Wireshark. Task 3. Download TCP Dump Capture Files from the SteelHead Objective In this task, you will download the recently created TCP Dump capture files from the SteelHead Web UI. The TCP Dump configured earlier created capture files for both the LAN and WAN interfaces. Each of these capture files are saved as a .cap0 file which will be analyzed using the free Wireshark packet analysis tool. Detailed Steps Use the SteelHead Web UI browser tab that you left open in the previous task. Refresh your browser window. In the table of stored TCP dumps, you will see two new capture files for the LAN and WAN interfaces. You will notice that the file name is formatted using the following syntax: <hostname>_<interface>_<your-dump-name>.cap0 Expand each capture file and click it's Download link. In the pop-up, click the Save button (will vary slightly between Firefox and Chrome): Ensure both files are downloaded and note their location, usually the Downloads folder or the Desktop. Review Task 4. Use Wireshark to Analyze TCP Dump Capture File Objective In this task, you will use Wireshark to analyze the TCP Dump capture files that you downloaded in the previous task. In the eLab environment, Wireshark has been installed on the Windows client, n21-pc. Although this task assumes that you already have some familiarity with the Wireshark product, the steps in this task will provide a step-by-step guide to allow you to analyze the packet capture. Detailed Steps Using your Windows desktop client, click the Windows icon at leftmost of the Task Bar and start typing \"wireshark\". On the Search pop-up, select Wireshark 3.2.0 (as in screenshot below, though version may differ slightly in your environment). In the Wireshark title bar, select File > Open . Navigate to the file location (Download directory is easily accessed via Quick access link), select the lan0_0 capture file that you saved in the previous task, and click Open . Launch a second Wireshark window, as before, and open the wan0_0 capture file. You will have both capture files open, each in a separate Wireshark window. In the lan0_0 trace window, type http in the Filter field and click Apply . This filter displays only packets containing HTTP traffic, which is just what we're looking for. Take a few moments to review the filtered results and explore additional Wireshark tools, such as the Statistics > Flow Graph , Statistics > TCP Stream Graphs , or Statistics > HTTP menu options. Close the Flow Graph (if open) and, back in the main Wireshark window of the lan0_0 capture, scroll through the packets in the Packet List pane (the top one) to find the first \"GET / HTTP/1.1\". In the Packet Details pane (the middle one), expand the TCP fields, then right-click on Source Port and select \"Apply as Column\". Identifying this connection's Source Port allows us to more easily follow this connection's packets when we open the WAN-side packet capture. In the screenshot below we see Source Port 49835. Clear the Wireshark filter and locate the SYN packet whose Source Port corresponds to the HTTP Get. In the screenshot below you will see packet 31 (top in list) shows SYN (and ECN & CWR, which are not currently interested in) with Source Port 49835; this packet we will locate in the wan0_0 capture to identify what, if anything, was changed by the n120-sh1 SteelHead (SH). While you are viewing this packet, it may be enlightening to note what the client set as TCP Options, to allow a more clear picture of any changes made by the client-side SteelHead. You may also note packet numbers 36 and 37 in the screenshot as the SYN/ACK and ACK for this connection; these had to complete before the HTTP GET we first looked at, in packet 43, could be sent by the client's browser. Switch to the Wireshark wan0_0 trace window, type tcp.options.rvbd.probe in the Filter field and click the Apply arrow at far right of the filter field. Look for the \"S+\" in the Info field of the packet who's Source Port matches that noted in the lan0_0 capture (if it helps, you can add Source Port as a column, as before). You are isolating the same SYN packet the client sent to initiate this connection, but we now see it after being handled by the client-side SH. Peruse the TCP Options of this packet to note if any client-set options were altered. To explore the Enhanced Auto Discovery process further, click on each of the filtered packets and expand the Transmission Control Protocol > Options entry in the Packet Details pane. Search the TCP Options field of the S+, SA++, and SA+ packets to ensure you understand how the client- and server-side SteelHeads leverage the TCP Options field to auto-discover each other. Note that selecting a TCP Option in the Packet Details pane highlights the corresponding hexadecimal-formatted payload in the Packet Bytes pane (bottom panel); useful to verify the first byte of Riverbed EAD probes use 0x4c. With auto-discovery understood, select the first SA+ packet, note it's packet number (on the left-most column) and clear the Wireshark display filter by selecting the x at the filter's right-hand edge. You should find the subsequent packets show the client-side SteelHead ARP for it's default gateway, then send the SYN packet to the server-side SteelHead's in-path IP address over tcp/7800. This begins the correct-addressed inner channel to establish optimization between the SteelHead appliances. Once complete, exit out of both Wireshark application windows. Task 5. Change the Transparency Mode to Full Transparency Objective We will now set WAN Visibility Mode for tcp/80 connections to the n31-fil server to Full IP and Port Transparency, then capture packets to analyze TCP Options. Recall that transparency mode, like every in-path rule feature, is always configured on the client-side SteelHead. Detailed Steps Return to the Web GUI for n120-sh1. Navigate to OPTIMIZATION > NETWORK SERVICES > In-Path Rules Click Add a New In-Path Rule , and configure these settings Source Subnet = All IPv4 Destination Subnet = 10.1.31.130/32 Destination: > Port: > Specific Port: 80 WAN Visibility Mode = Full Transparency Description = \"full trpy to n31-fil:80\" Leave all other settings at their default values and click Add Review Task 6. Configure and Start a New TCP Dump Objective In this task we will create a new TCPDump and generate more traffic which, this time, should be optimized using Full Transparency. We then examine these trace files using Wireshark. Detailed Steps Staying on the GUI for n120-sh1 navigate to Reports > Diagnostics > TCP Dumps . As before, click the Add a New TCP Dump button and specify the following capture criteria. Again, leave any unlisted fields at the default value. Though we will add a bit more time, check that the browser tab for Datacenter Hosts > n31-fil File Server (HTTP) is still open; if it is not then open it, take a quick glance at where the file \"DutchGoldenAge.ppt\" is, and return here to complete the capture. Capture Name: FTprobes In-Path Interfaces: lan0_0 (Check) wan0_0 (Check) Capture Duration: 120 Seconds Click Add to start the TCP Capture. Verify that FTprobes appears under TCP Dumps Currently Running : Return to the tab for Datacenter Hosts > n31-fil File Server (HTTP) and refresh it. Click the Presentations folder and then right-click the \"DutchGoldenAge.ppt\" file and, when prompted, save the file. It technically does not matter which file you choose or even where you have stored it, the important thing is that we have generated some traffic: If you act quickly you should be able to view this connection on n120-sh1 in the Reports > Networking > Current Connections Report . HTTP connections are typically short lived, so you'd have to view it before the transfer finishes. If you can, open this report and expand the optimized connection. You should see that the connection is using Full Transparency. Should you miss this first transfer, feel free to perform another with a file you've not yet transferred; this should allow you time to catch it in the Current Connections Report. Review Task 7. Use Wireshark to Analyze the New TCP Dump Capture File Objective In this, the final task of this lab, we will once again use Wireshark to analyze the TCP Dumps we generated in the previous task. Detailed Steps Download both capture files using the steps you performed in Task 3. Open a new Wireshark window and select File > Open . Select the lan0-0 capture file that you just saved. Ensure you open FTprobes rather than the EADprobes file! Repeat this step for the corresponding wan0_0 capture file in a separate Wireshark window. In the lan0_0 trace window, type http in the Filter field , click the Apply arrow. Take a few moments to review the filtered results, they should look remarkably similar to those you saw in Task 4. Now, in the wan0_0 trace window, type tcp.options.rvbd.trpy in the Filter field and click the Apply arrow. This filter will display only the packets containing the Riverbed Transparency TCP option, which as you recall (and which you can now validate) begins with hexadecimal entry 4e . Remember, Full Transparency embeds the inner channel addressing information in the TCP options field, and it is this information we are now interested in. You should see a lot of green packets between the IP addresses 10.1.21.110 and 10.1.31.130, all of them with TRPY in the Info field. Click on one of these packets and expand the Transmission Control Protocol > Options entry in the lower contents pane. Search the TCP Options field and its corresponding hexadecimal-formatted payload in the lower two panels. You should be able to see the 'real' endpoint IP addresses (of the client- and server-side SteelHead in-path interfaces) embedded within the TCP Options field: Take a few moments to review the filtered results. Can you understand what is going on here? if not, discuss this with your instructor. Extra Credit Finally (you may need to change the filters) compare an equivalent packet (from a source IP to destination IP) from the lan0_0 file with one from the wan0_0 capture file paying particular attention to the client IP addresses its associated MAC address. See if you can answer the following questions: Does the SYN+ packet seen on the WAN side of n120-sh1 have the same source MAC address as it's corresponding SYN packet seen on the LAN side? (HINT: use TCP source port to ensure same packet for same connection is being compared) For a given connection in full transparency, do the data packets (packets after the TCP handshake) on the WAN side of the client-side SteelHead have the same source MAC address as data packets on the LAN side? (HINT: look for TCP option 0x4e on the WAN-side trace) Consider the MAC address corresponding to the IP address of the server (10.1.31.130), from the client's perspective. Will the client see a change in the MAC address for the \"server\" depending on SYN, SYN+ and data packets? An important concept to understand about the above questions is: how is the SteelHead terminating and bridging traffic? How are SYN+ packets actually handled? Which MAC address does the client-side SteelHead use when it sends SYN+ packets? For the inner-channel of a full transparent connection, who is really talking to whom? Once complete, exit out of both Wireshark application windows. End of Scenario Congratulations! You have successfully created TCP dumps on SteelHead appliances, and from those have identified and traced EAD packets and Full Transparency connections. For more information on Wireshark or to learn more about packet capture, it is recommended to visit www.wireshark.org to download a free copy for yourself.","title":"Lab 3"},{"location":"lab-4/","text":"HOL1142: Optimizing HTTPS (SSL) Traffic with SteelHead Introduction Overview SSL provides a way for client and server applications to communicate securely over a potentially insecure network. It provides authentication and prevents eavesdropping and tampering. In the most common use case, we use SSL to transport HTTP traffic and provide one-way identification: only the web server authenticates itself to the web browser. In response to the Hello message, the server sends back its certificate. The certificate contains the server's public key, some identifying information about the server (such as its name and location), and a digital signature of all this information. This digital signature is issued by an entity called a Certificate Authority (CA) that both the client and the server trust, and it serves as proof that no one has tampered with the certificate. Upon receiving the certificate, the client verifies that it has not been tampered with and that it does belong to that particular server. Then, the client generates a random number N, encrypts it with the server's public key, and sends it to the server. At this point, both the client and the server use the same function to derive the session key, ks, from N. In the simplest case, after the initial SSL handshake between the client and the server and the creation of the session keys, the same session keys are used for the duration of the session, without the need to go through another SSL handshake. Use Case As more and more applications are using HTTPS, though you may have CIFS & HTTP optimization enabled and working spendidly, much of your traffic may not be optimized since it is HTTPS (SSL). So let's get that SSL optimized! Solution At a high level, SteelHeads terminate an optimized SSL connection by making the client think it is communicating to the server and making the server think it is talking to the client. In fact, the client and server are talking securely to the SteelHeads. You require some special provisioning to accomplish optimization that appears transparent to the client. To enable SSL connection termination, you must configure the server-side SteelHead to include digital certificates and private keys in order to emulate the servers. When the SteelHead poses as the server, there does not need to be any change to either the client or the server. The security model is not compromised \u2014 the optimized SSL connection continues to guarantee server-side authentication and prevents eavesdropping and tampering. When transferring data over the WAN on behalf of an optimized SSL connection, the client-side and server-side SteelHeads ensure that their inner connection provides all the security features the original SSL connection would have, had it not been optimized. SteelHeads accomplish this by establishing their own SSL connection between themselves. To secure the inner SteelHead channel, you must configure each SteelHead to trust the certificate of the peer SteelHead (secure peering); there are various methods to accomplish this. Lab Objectives Ensure required DNS and Connect to the Branch SteelHead Web UI (Web UI). Configure a CA and certificate and install on client and server. Verify SSL License on Branch SteelHead Enable SSL Optimization on Branch SteelHead Connect to the Datacenter SteelHead Web UI (Web UI) Verify SSL License on Datacenter SteelHead Enable SSL Optimization on Datacenter SteelHead Import Web Server SSL Certificates into Datacenter SteelHead Import CA Certificate into Datacenter SteelHead Configure SteelHead Peering Trust Create an In-Path Rule for SSL Traffic to N31-FIL Web Server Verify SSL Optimization Troubleshoot SSL Connection Reconfigure to use a proxy certificate Task 1. Ensure required DNS and Connect to the Branch SteelHead Web UI (Web UI) Objective In this task, you will ensure n21-pc can resolve the common name (CN) for the SSL server; a critical step for secure browsing to SSL-secured web sites. In production networks, name resolution is usually performed by DNS services, but it is useful to know how to point hosts to specific hostnames in the event DNS is not configured for a given host. Lastly, you will log into the 'branch' SteelHead, n120-sh1 , to prepare for subsequent configuration. Detailed Steps First, we add the n31-fil name, FQDN, and IP address to the n21-pc hosts file. On the n21-pc, click the Start button and then type Notepad . Right-click and then select Run as Administrator : Open the hosts file, located in C:\\Windows\\System32\\drivers\\etc . In this folder you will need to change the view from \"Text Documents (*.txt)\" to All Files (*.*) in Notepad in order to see it: Add the following line to the end of the file: 10.1.31.130 n31-fil n31-fil.cyberdyne.corp Save the file and close Notepad. Next, open Chrome or Firefox and use the bookmarks toolbar to navigate to Branch Optimization > n120-sh1 SteelHead 1 (Path 1) . When presented with the login screen, use the username admin and password password . You will be directed to the SteelHead dashboard. Review You have ensured required domain names can be resolved on n21-PC, and accessed the user interface of the client-side SteelHead. Task 2. Create and configure your own Certificate Authority (CA) in Linux Objective In this task we will create a Certificate Authority (CA) in Linux using OpenSSL. Once we have done this we will use our new CA to digitally sign an SSL certificate for our web-server. We can then import our CA certificate into our browser so it trusts SSL certificates signed by the CA. Detailed Steps Using your Windows client PC, open mRemoteNG . In the sidebar, double click on Datacenter - Tier 3 - Hosts > N31-FIL File Server to open an SSH connection to the server. Click inside of the black console window to activate the SSH session. You will need to select YES to accept the risk of using a self-signed certificate with SSH. Login using the username root and password myeLab! . Create a new CA certificate using the following command: openssl req -x509 -nodes -newkey rsa:2048 -keyout ca.key -out ca.cer -days 1095 At the resulting prompts, fill in your CA details as follows: Country Name (2 letter code) [AU]: US State or Province Name (full name) [Some-State]: California Locality Name (eg, city) []: San Francisco Organization Name (eg, company) [Internet Widgits Pty Ltd]: Riverbedlab Organizational Unit Name (eg, section) []: Training Common Name (e.g. server FQDN or YOUR name) []: zaphod.cyberdyne.corp Email Address []: ford@cyberdyne.corp Type ls ; you should see some files. The ones we are interested in are ca.cer and ca.key . There should be a couple of other certificate files in the directory but you can safely ignore them. We now have a CA which we can use to sign certificates. We will now use this to sign the certificate for our server (n31-fil). To do this we will create a certificate signing request (CSR) and then sign this request with our newly generated CA key. To create the CSR, start by typing the following command: openssl req -newkey rsa:2048 -nodes -keyout n31-fil.key -out n31-fil.csr At the resulting prompts, fill in the details for your new certificate: Country Name (2 letter code) [AU]: US State or Province Name (full name) [Some-State]: California Locality Name (eg, city) []: San Francisco Organization Name (eg, company) [Internet Widgits Pty Ltd]: Riverbedlab Organizational Unit Name (eg, section) []: Training Common Name (e.g. server FQDN or YOUR name) []: n31-fil.cyberdyne.corp Email Address []: ford@cyberdyne.corp A challenge password []: <just press enter> An optional company name []: <just press enter> The key field here is the Common Name (CN). This must match what is typed in on the browser window or it will simply not work. Name resolution is essential for SSL. Sign the request using your CA key: openssl x509 -req -days 1095 -in n31-fil.csr -CA ca.cer -CAkey ca.key -CAcreateserial -out n31-fil.cer We now need to configure Apache to use this newly signed certificate. Fortunately, the server you are currently connected to is also our web server so this step is pretty straightforward. Type the following commands to place the certificate and key into the appropriate directories: cp n31-fil.cer /etc/ssl/certs cp n31-fil.key /etc/ssl/private We now need to edit the SSL configuration file within Apache to point to these new certificates. This requires some manual editing of the default-ssl configuration file. We are going to use the nano text editor as it is simple, but feel free to use vi if you prefer. nano /etc/apache2/sites-enabled/default-ssl Within nano, search (or scroll down) for the two lines which contain the paths to the certificate files: SSLCertificateFile /etc/ssl/certs/ssl-cert-snakeoil.pem SSLCertificateKeyFile /etc/ssl/private/ssl-cert-snakeoil.key Change these lines to the following: SSLCertificateFile /etc/ssl/certs/n31-fil.cer SSLCertificateKeyFile /etc/ssl/private/n31-fil.key Hit ctrl+o keys, then 'Enter' to save the changes, and then ctrl+x to exit. You will next add the ServerName variable for correct virtual host resolution. nano /etc/apache2/conf.d/fqdn Add the following line to the empty file. ServerName n31-fil.cyberdyne.corp Hit ctrl+o keys, then 'Enter' to save the changes, and then ctrl+x to exit. Finally, restart the Apache service to use the new configuration. service apache2 restart Good to note any errors here, though a warning about NameVirtualHost should not cause problems in our scenario. Minimize your SSH client and then, via the Start Menu, click on FileZilla . In the menu bar enter the following information and then click on QuickConnect : Host: 10.99.31.130 Username: root Password: myeLab! Port: 22 In the Filename box on the Remote Site scroll down and drag the following files to the Desktop on the Local Site : ca.cer n31-fil.cer n31-fil.key Minimize FileZilla and then return to Firefox. Click the hamburger button on the top right of the Firefox window to bring up the menu: Click Options and then Privacy and Security on the menu on the left. Scroll to the bottom to the Certificates section. Click on View Certificates and in the resulting window select the Authorities tab as shown: Click Import at the bottom (may need to scroll down) and then select the ca.cer file on the Desktop. Click Open . At the resulting window click the box next to Trust this CA to identify websites : Click OK . If you scroll down in the Authorities window you should be able to see the Riverbedlab certificate which you just a short while ago created: Finally, open a new tab in Firefox and type the following URL: https://n31-fil.cyberdyne.corp The page should load without any errors and the little padlock should be closed and gray. Click on it. With recent versions of Firefox, a gray padlock indicates that you're definitely connected to the website whose address is shown in the address bar, and the connection between Firefox and the website is encrypted. What it also indicates is that the site is not using a (more expensive) Extended Validation SSL certificate, which is now what Firefox's green padlock is reserved for. Click on the arrow and then More information . You should see the following: Click View Certificate . You should finally see the following: Review In this in-depth task, we have setup a Linux server as a certificate authority, and then used this to sign a certificate for our web server. We then reconfigured our web server to use this signed certificate and then imported the CA certificate into our browser. The result is that our website is now trusted via it's certificate signed by a trusted CA. All of this will be important for later steps when we configure our SteelHeads to optimize the SSL traffic to/from this server. The principles we have implemented here will be put to good use in the later tasks. Do not delete the certificate files you have stored on your desktop - you will need them for later tasks. Task 3. Verify SSL License on Branch SteelHead Objective In this task, you will verify the Enhanced Cryptographic License Key is valid on the branch SteelHead appliance. The SSL License is called the Enhanced Cryptographic License Key, because it also activates RiOS data store encryption and can create secure inner channels while optimizing encrypted MAPI and SMB-signed traffic (even if the SteelHeads aren\u2019t configured for optimizing user SSL traffic). Detailed Steps Using the N120-SH1 Branch SteelHead Web UI, navigate to Administration > Maintenance > Licenses . Locate the Enhanced Cryptographic License Key in the list. Under the Status column, verify the license key is Valid . No action is required, it is best practice to visually check these keys are valid prior to configuring SSL. Review If you don\u2019t have a valid Enhanced Cryptography License Key, visit https://sslcert.riverbed.com and follow the instructions. Task 4. Enable SSL Optimization on Branch SteelHead Objective In this task, you will enable SSL optimization on the branch SteelHead. The SteelHead can securely decrypt, optimize, and then reencrypt SSL traffic. To configure SSL support, you are not required to make configuration changes on the client or server hosts; clients continue connecting to the same server name or IP address. Detailed Steps Using the N120-SH1 Web UI, navigate to Optimization > SSL > SSL Main Settings Check the Enable SSL Optimization checkbox and click the Apply button. In the top right, click the Save to Disk button to write your change to NVRAM. Restart the optimization service. Remember that in a production environment the optimization service should only be restarted during a change window, as all connections currently optimized by that SteelHead would be disrupted. Review SSL must be enabled on both the client-side and server-side SteelHeads for SSL optimization to work. In the upcoming tasks we will enable SSL on the server-side SteelHead. Task 5. Connect to the Datacenter SteelHead Web UI (Web UI) Objective In this task, you will login to access the Datacenter SteelHead appliance using the username admin and password password . Detailed Steps Open a new tab in Firefox. Use the bookmarks toolbar to navigate to Datacenter Optimization > n130-sh1 SteelHead 1 (Path 1) . When presented with the login screen, use the username admin and password password . You will be directed to the N130-SH1 SteelHead dashboard. Review You have logged in to both the Branch and Datacenter SteelHead Web UIs, allowing you to configure the respective appliances by simply switching browser tabs. Task 6. Verify SSL License on Datacenter SteelHead Objective In this task, you will verify the Enhanced Cryptographic License Key is valid on the datacenter SteelHead appliance. Detailed Steps Using the N130-SH1 Datacenter SteelHead Web UI, navigate to Administration > Maintenance > Licenses . Locate the Enhanced Cryptographic License Key in the list. Under the Status column, verify the license key is Valid . No action is required, it is best practice to visually check these keys are valid prior to configuring SSL. Review If you don\u2019t have a valid Enhanced Cryptography License Key, visit https://sslcert.riverbed.com and follow the instructions. Task 7. Enable SSL Optimization on Datacenter SteelHead Objective In this task, you will enable SSL optimization on the datacenter SteelHead. Detailed Steps Using the N130-SH1 Datacenter SteelHead Web UI, navigate to Optimization > SSL > SSL Main Settings Check the Enable SSL Optimization checkbox and click the Apply button. In the top right, click the Save to Disk button to write your change to NVRAM. Restart the optimization service. Remember that in a production environment the optimization service should only be restarted during a change window, as all connections currently optimized by that SteelHead would be disrupted. With SSL enabled on both SteelHead client- and server-side appliances, you can configure the remaining tasks for SSL optimization without restarting the optimization service. Review You have successfully enabled SSL optimization on both the branch and datacenter SteelHead appliances. Task 8. Import Web Server SSL Certificate and Key into Datacenter SteelHead Objective In this task, you will import the SSL certificate and private key for n31-fil.cyberdyne.corp into the datacenter SteelHead. Detailed Steps Using the N130-SH1 Datacenter SteelHead Web UI, navigate to Optimization > SSL > SSL Main Settings. Scroll down to the SSL Server Certificates section and click Add a New SSL Certificate . In the Name field, type in n31-fil . Leave the Import Certificate and Private Key option selected and scroll down. In the Certificate section, select the Upload (PKCS-12, PEM or DER formats) option. Click the Browse button, navigate to the n31-fil.cer file you downloaded earlier and click Open . Scroll further down the screen to the Separate Private Key field. Under Upload (PEM or DER formats) click Browse... and now select the n31-fil.key file. Scroll slightly further down and click the Add button to save the certificate to the SteelHead. Though the import was successful, and sufficient for our scenario, it's worth reading the warning at the top of the window which sheds more light on the certificate trust process: Review You have successfully imported the web server's SSL Certificate and Key into the datacenter SteelHead. Task 9. Import CA Certificate into Datacenter SteelHead Objective Remember that the server-side SteelHead acts as a client to the SSL server. For this to work, the SteelHead must trust the backend server (which for us is the web-server n31-fil ). This means that our server-side SteelHead has to be able to verify the web-server's certificate. In order to do this we will to import the CA certifcate that signed the web server's certificate, into the server-side SteelHeads Certificate Authorities list. Detailed Steps Remaining within the N130-SH1 GUI, navigate to Optimization > SSL > Certificate Authorities . Click Add a New Certificate Authority . If desired, add a Local Name such as n31-fil_CA ; makes the displayed CA Name much easier to identify than the long number string such as you'll note in the screenshot below. Select the Local File option and click Browse . Navigate to the ca.cer file and click Open . Click Add Scroll down the list, you should see an entry similar to the following: Note that the certificates are displayed in alpha-numeric order, so if you added a Local Name then it will be sorted accordingly. Review You have now imported the CA certificate used to sign the certificate on the web-server. This is for the same trust process as when we earlier imported ca.cer into Firefox: the n130-sh1 SteelHead (just as the Firefox browser earlier) can now use this CA certificate to verify the identity of the n31-fil server. Task 10. Configure SteelHead Peering Trust Objective In this task, you will add a trusted peer certificate to both the Branch and Datacenter Steelheads to create a secure inner channel. You will need to verify the expiration date of both certificates. If they have expired, ensure that you generate new ones before proceeding with the next steps! We need to configure each SteelHead to trust its peer in order to establish a secure inner channel for secure peering. When your SteelHeads were first deployed, they self-generated an SSH key pair that can be used for secure peering. We will copy the public key for each SteelHead onto the other SteelHead's list of trusted peers. There are many ways to accomplish this secure peering relationship, and this admittedly is not the most scalable (SCC provides that), but it is perhaps the simplest in explaining the process. Detailed Steps Using the N120-SH1 Branch SteelHead Web UI, navigate to Optimization > SSL > Secure Peering (SSL) , and in the Certificate Details box, check the Expires On: date in the Validity section. If the certificate is still valid you can proceed to Step 4. Otherwise, to replace the existing certificate with a new one, in the Certificate box click on the Replace tab. Then select \"Generate Self-Signed Certificate and New Private Key\", and enter the following in the details: Common Name: n120-sh1 Organization Name: Riverbed Technology, Inc Organization Unit: RiverbedLab Locality: San Francisco State: California Country: US Email Address: ford@cyberdyne.corp Validity Period: 3650 Scroll down and click \"Generate Certificate and Key\". Perform the same for N130-SH1 using the following details: Common Name: n130-sh1 Organization Name: Riverbed Technology, Inc Organization Unit: RiverbedLab Locality: San Francisco State: California Country: US Email Address: ford@cyberdyne.corp Validity Period: 3650 On the N120-SH1 , under Optimization > SSL > Secure Peering (SSL) , select the PEM tab. Copy the N120-SH1 secure peering (SSL) certificate, including the -----BEGIN CERTIFICATE----- and -----END CERTIFICATE----- lines. Going to the N130-SH1 Datacenter Steelhead Web UI, navigate to Optimization > SSL > Secure Peering (SSL) . Slide down to the Peering Trust section, and click Add a New Trusted Entity . Select the Trust New Certificate radio button, and if desired add the optional name n120-sh1 . Select Cert Text radio button, and paste the N120-SH1 secure peering (SSL) certificate into the text box. Click Add and you will see notification that the certificate has been added. Repeat the steps above to copy the N130-SH1 Datacenter SteelHead secure peering (SSL) certificate onto N120-SH1 as a trusted peer. If you see the warning, \"not yet active\", (implying the date/time on a certificate is 'in the future' for the SteelHead you're adding it to; in essence: their system clocks are out of sync) ignore it for now. Review You have successfully established a trusted peering relationship between the branch and datacenter SteelHead. Task 11. Create an In-Path Rule for SSL Traffic to N31-FIL Web Server Objective In this task you will configure the client-side SteelHead to attempt optimization of specific SSL traffic. To do this you will create an in-path rule on n120-sh1 , instructing it to perform auto-discovery for tcp/443 traffic from the N21 San Francisco branch ( 10.1.21.0/24 ) to the N31-FIL web server ( 10.1.31.130/32 ). SSL certificates must be configured on the datacenter SteelHead for each web server we want to optimize; by default a server-side SteelHead will pass through SSL traffic unless explictly destined for a known server's IP address that we have the SSL certificates for. Detailed Steps Using the N120-SH1 Web UI, navigate to Optimization > Network Services > In-Path Rules Click Add a New In-Path Rule , and enter the following settings: Source Subnet: 10.1.21.0/24 Destination Subnet: 10.1.31.130/32 Port: 443 Position: Start Click the Add button. Recall that a default rule causes tcp/443 to be pass-through, so we need to add our rule above the 'Secure' pass-through rule. Note also that, because we are focusing on tcp/443 traffic, we do not need to tell the SteelHead to perform SSL pre-optimization - that is automatic; just as it automatically performs latency optimization HTTP for tcp/80, and CIFS for tcp/445. Save your configuration. Review You have configured an in-path rule to explicitly allow HTTPS (tcp/443) traffic from the 10.1.21.0/24 network, destined for the N31-FIL web server (10.1.31.130), to be optimized. Task 12. Verify SSL Optimization Objective In this task, we will perform an HTTPS file transfer to see if the SSL connection is being optimized. Keep in mind that HTTPS connections are foundationally akin to HTTP in that they can close very quickly (often within a few seconds), so you'll need to refresh the Current Connections report quickly to identify the connections. Sometimes the Traffic Summary or Optimized Throughput Reports more readily show that SSL is being optimized. Detailed Steps Using the N130-SH1 Datacenter SteelHead Web UI, navigate to Reports > Networking > Current Connections . In Firefox , open a new tab and navigate to https://n31-fil.cyberdyne.corp . Click the little gray padlock next to the URL. As we have imported the actual certificate and key this should be identical to what you observed back in task 2. Navigate to the Presentations directory and find a rather large file, >15MB or so, to download. Easiest method is to right-click the file and click \"Save Link As...\", accept the default Downloads directory and click Save . Using the N130-SH1 Datacenter SteelHead Web UI, and click Update to refresh the list of connections. If this is done quickly, you may be able to see the connection, however the connection will not display if it has already completed. Navigate to Reports > Networking > Optimized Throughput , and for completeness you can filter the Port to 443 SSL Review You should have noticed in one report or another that SSL optimization is working. To prove it you could download the same file again via FTP (open FileZilla connection to n31-fil), or CIFS (map a share to n31-fil), and it should download in just seconds. If by chance the SSL optimization failed, in the next task we will be troubleshooting. Task 13. Troubleshoot SSL Connection Objective If your SSL optimization worked in the prior task, Congratulations! You can review this section to prepare yourself for more challenging environments. If your SSL optimization verification in the prior task did not succeed, then this task leverages your knowledge of the SteelHead Web UI, along with the Current Connections Report and System Logs, to diagnose why the SSL optimization isn't working. The key here, as in all troubleshooting, is determining where the problem actually is, and as there are multiple configuration elements, you may need to work through more than one issue. It is suggested to use the Current Connection Report's \"Passthrough reason\" and the System Log as guides. Suggested Steps Diagnose the Current Connections Passthrough reason \" SYN on WAN \", for instance, implies the server-side SteelHead did not see a probed SYN; is the client-side SteelHead in-path rule correct? \" SSLINNER_FAILURE \" indicates a peering trust issue; double-check the Peering Trust table. Use the System Logs to diagnose the issue \" SSL handshake between server-side SteelHead appliance and server has failed \" implies, well, just that; was the ca.cer certificate installed correctly? Verify that your Certificate Authority is properly configured or create a new one. Verify that each SteelHead is in the other's White list in Secure Peering Check whether the server-side SteelHead is bypassing the server, either at the bottom of the Optimization > SSL > SSL Main Settings page, or by using the CLI command show protocol ssl backend bypass-table Use the Riverbed Support Knowledge Base to search for the error messages Task 14. Use a Proxy Certificate for the Server Objective In the real world it is unlikely that you will use the actual private key and certificate for the server itself. What often occurs is creation of a new certificate key-pair, signed by a CA trusted in the user environment, and imported as a proxy for the server. From the point of view of this lab you have completed nearly all of the required steps in task 2, including the essential task of setting up a trusted Certificate Authority, so this task should be pretty straightforward. Detailed Steps Using the N130-SH1 Datacenter SteelHead Web UI, navigate to Optimization > SSL > SSL Main Settings . In the SSL Server Certificates section, delete the existing server certificate for n31-fil . We will now generate a new proxy certificate and key. Open mRemoteNG and select Datacenter - Tier 3 - Hosts > n31-fil File Server in the sidebar. Username: root Password: myeLab! Type the following command to create a new proxy certificate: openssl req -newkey rsa:2048 -nodes -keyout proxy.key -out proxy.csr At the resulting prompts enter the details for your proxy certificate: Country Name (2 letter code) [AU]: GB State or Province Name (full name) [Some-State]: North Yorkshire Locality Name (eg, city) []: Scarborough Organization Name (eg, company) [Internet Widgits Pty Ltd]: Proxy Moxy Organizational Unit Name (eg, section) []: Training Proxy Common Name (e.g. server FQDN or YOUR name) []: n31-fil.cyberdyne.corp Email Address []: dave@cyberdyne.corp A challenge password []: <just press enter> An optional company name []: <just press enter> Note how different the details were from the original. This is intentional and we will see why in a later step. The important part is ensuring that the Common Name, as before, correctly identifies the server in question. Now we just need to sign it, using our trusted CA, with the following command: openssl x509 -req -days 1095 -in proxy.csr -CA ca.cer -CAkey ca.key -CAcreateserial -out proxy.cer As this is a later task we can go just a bit deeper. Let us combine the certificate and key into a single PEM file. This will make the import to the server-side SteelHead a bit easier. Type the following command: cat proxy.cer proxy.key > proxy.pem Using FileZilla copy proxy.pem to your Windows Desktop. Host: 10.99.31.130 Username: root Password: myeLab! Port: 22 Using the N130-SH1 Datacenter SteelHead Web UI, navigate to Optimization > SSL > SSL Main Settings . Under the section SSL Server Certificates , click Add a New SSL Certificate and, if desired, name it something useful such as n31-fil . In the Certificate section, leave Upload selected and click Browse . Navigate to your Desktop and select the proxy.pem file. Scroll down to the Private Key section, and select This file includes the Certificate and Private Key . Scroll down and click Add . The new certificate should appear in the SSL Server Certificates list. Expand it by clicking the little triangle next to the certificate name. You should obtain something similar to the following: Note that a critical part of this is the signing CA must be trusted by the client, or the client will of course not trust the certificate offered by the server-side SteelHead, and the SSL connections to that server would end up in pass-through. Open a new tab in Firefox and navigate to https://n31-fil.cyberdyne.corp . Click the little gray padlock icon and then click the arrow next to the certificate name. When prompted click More Information to obtain the following. Click View Certificate . Note that this is NOT the certificate on the server. During SSL optimization, the Windows client performs a handshake with the server-side SteelHead, not the server itself, so it has been given the proxy certificate rather than the actual one; trusted because the CA that signed the proxy cert has it's CA certificate in the client's trusted Authorities directory. Create some SSL traffic by downloading a file or two from within Firefox. Then navigate to Reports > Optimization > Optimized Throughput and ensure that you have selected an appropriate time window. You should see some throughput scrolling by for Port 443 SSL . Review You have reconfigured SSL to use a signed proxy certificate which is trusted by the clients. Extra Credit SSL Optimization After completing the SSL configuration on both SteelHeads and restarting the optimization service, access the secure server from the web browser. These events take place in a successful optimization: In the Web UI, the Current Connections report lists the new connection as optimized without a red protocol error. In the Web UI, the Traffic Summary report displays encrypted traffic (typically, HTTPS). Verify that the back-end server IP appears in the SSL Discovered Server Table (Optimizable) in the SSL Main Settings page. Note: Because all the SSL handshake operations are processed by the server-side SteelHead, all the SSL statistics are reported on the server-side SteelHead. No SSL statistics are reported on the client-side SteelHead. Monitoring SSL Connections Use these tools to verify SSL optimization and to monitor SSL progress: On the client web browser, click the Lock icon to obtain certificate details. The certificate must match the proxy certificate installed on server-side SteelHead. In the Current Connections report, verify the destination IP address, port 443, the Connection Count as Established (three yellow arrows on the left side of the table), SDR Enabled (three cascading yellow squares on the right side of the table), and that there\u2019s no Protocol Error (a red triangle on the left side of the table). In the SSL Statistics report (on the server-side SteelHead only) look for connection requests (established and failed connections), connection establishment rate, and concurrent connections. Monitoring Secure Inner Channel Connections Use these tools to verify that secure inner channels are in use for the selected application traffic types: In the Current Connections report, look for the Lock icon and three yellow arrows, which indicate the connection is encrypted and optimized. If the Lock icon is not visible or is dimmed, click the Details icon (gray triangle) to view a failure reason that explains why the SteelHead is not using the secure inner channel to encrypt the connection. If there\u2019s a red protocol error, click the Details icon to view the reason for the error. Search the client-side and server-side SteelHead logs for \" SSL \" along with ERR and WARN. Whenever using self-signed peering certificates, check that the SteelHeads appear in the Self-Signed Peer White List: on both client-side and server-side SteelHeads. Certificate Authority Tips & Tricks We have covered most of these steps during the lab, but it is worth having a number of useful commands set down for reference. There is always more than one way to do the same thing in Linux so some of these commands are slightly different from those in the lab. To Create Certificate Authority (Cert & Key): openssl genrsa -out CAKeyCyberdyne.key 4096 openssl req -new -x509 -days 1460 -key CAKeyCyberdyne.key -out CACyberdyne.crt Then create a Certificate signing request on the server (*.csr file). Then back to openSSL to sign it (the *.csr file) with the new Certificate authority that we have just created. openssl genrsa -des3 -out cyberdyne-n31-fil.key 1024 openssl req -new -key cyberdyne-n31-fil.key -out cyberdyne-n31-fil.csr openssl x509 -req -days 1460 -in cyberdyne-n31-fil.csr -CA CACyberdyne.crt -CAkey CAKeyCyberdyne.key -set_serial 123456 -out cyberdyne-n31-fil.crt Then convert to PKCS12 Format (*.pfx file) openssl pkcs12 -export -out cyberdyne-n31-fil.pfx -inkey cyberdyne-n31-fil.key -in cyberdyne-n31-fil.crt -certfile CACyberdyne.crt Once you have a new certificate authority created and you've created your keys, you'll need to copy the keys to /etc/ssl/keys and /etc/ssl/private and update the Apache configuration file in /etc/apache2/sites-enabled/default-ssl with the new key paths.","title":"Lab 4"},{"location":"license-tiers/","text":"License Tiers","title":"License Tiers"},{"location":"license-tiers/#license-tiers","text":"","title":"License Tiers"},{"location":"mgmt-and-config/","text":"Management and Configuration Management is available on all interfaces by default Rest API for special purposes such as automation Graphical User Interface via HTTP / HTTPS MIB downloadable from the GUI Telnet (disabled by default) Rest API SNMP SSH BMC Best Practice: Always use the SCC. CLI Command Entry Modes User Enable Config Riverbed SteelHead Show Interface VCX255-A #sh int inpath0_0 Interface: inpath0 0 State: Up Interface type: ethernet IP address: 10 .1.30.125 Netmask: 255 .255.255.0 IPv6 link-local address: fe80::20c:29ff: fe28:b93d/64 MTU: 1500 HW address: 00 :0C:29:28:B9:3D Traffic status: Normal HW blockable: no Counters cleared date: 2019 /12/12 11 :43:00 RX bytes: 6526710 RX mcast packets: 51827 errors: 0 RX overruns: 100 TX bytes: 1548 Riverbed SteelHead configuration wizard VCX255-A ( config ) conf jump-start Step 1 : Hostname? ( VCX255-A1 ) Step 2 : Use DHCP on primary interface? [ no ] Step 3 : Primary IP address? [ 10 .1.30.25 ) Step 4 : Netmask? [ 255 .255.255.0 ] Step 5 : Default gateway? [ 10 .1.30.254 ] Step 6 : Primary DNS server? ( 10 .1.30.102 ) Step 7 : Domain name? [ training.local ] Step 8 : Admin password? Step 9 : SMTP server? Step 10 : Notification email address? Step 11 : Set the primary interface speed? [ auto ] Step 12 : Set the primary interface duplex? [ auto ] Step 13 : Would you like to activate the in -path configuration? [ yes ] Step 14 : In-Path IP address? ( 10 .1.30.125 ) Step 15 : In-Path Netmask? 1255 .255.255.01 Step 16 : In-Path Default gateway? [ 10 .1.30.254 ) Step 17 : Set the in -path:LAN interface aspeed? [ auto ] Step 18 : Set the In-path: LAN interface duplex? [ auto ] Step 19 : Set the in -path:WAN interface speed? [ auto ] Step 20 : Set the in -path: WAN Interface duplex? [ auto ] Network interface configuration interface aux description interface aux dhcp interface aux dhcp dynamic-dns no interface aux dhcpv6 no interface aux shutdown interface aux dhcpv6 dynamic-dns interface aux mtu \"1588\" interface aux speed \"auto\" interface inpath8 8 description \"\" no interface inpath8_8 dhcp no interface inpath8 8 dhcp dynamic-dns na interface inpath8_8 dhcpv6 no interface inpath8 8 dhcpv6 dynamic-dns no interface interface inpath0 8 force-Mdi-x enable inpath8_8 ip address 18 .1.58.125 /24 interface inpath8 8 mtu \"1588\" interface interface inpath8_8 napi-weight \"128\" inpath8_8 shutdown interface inpath8_8 speed \"auto\" no interface shutdown inpathB 8 txqueuelen \"188\" lo description","title":"Management and Configuration"},{"location":"mgmt-and-config/#management-and-configuration","text":"Management is available on all interfaces by default Rest API for special purposes such as automation Graphical User Interface via HTTP / HTTPS MIB downloadable from the GUI Telnet (disabled by default) Rest API SNMP SSH BMC Best Practice: Always use the SCC.","title":"Management and Configuration"},{"location":"mgmt-and-config/#cli-command-entry-modes","text":"User Enable Config","title":"CLI Command Entry Modes"},{"location":"mgmt-and-config/#riverbed-steelhead-show-interface","text":"VCX255-A #sh int inpath0_0 Interface: inpath0 0 State: Up Interface type: ethernet IP address: 10 .1.30.125 Netmask: 255 .255.255.0 IPv6 link-local address: fe80::20c:29ff: fe28:b93d/64 MTU: 1500 HW address: 00 :0C:29:28:B9:3D Traffic status: Normal HW blockable: no Counters cleared date: 2019 /12/12 11 :43:00 RX bytes: 6526710 RX mcast packets: 51827 errors: 0 RX overruns: 100 TX bytes: 1548","title":"Riverbed SteelHead Show Interface"},{"location":"mgmt-and-config/#riverbed-steelhead-configuration-wizard","text":"VCX255-A ( config ) conf jump-start Step 1 : Hostname? ( VCX255-A1 ) Step 2 : Use DHCP on primary interface? [ no ] Step 3 : Primary IP address? [ 10 .1.30.25 ) Step 4 : Netmask? [ 255 .255.255.0 ] Step 5 : Default gateway? [ 10 .1.30.254 ] Step 6 : Primary DNS server? ( 10 .1.30.102 ) Step 7 : Domain name? [ training.local ] Step 8 : Admin password? Step 9 : SMTP server? Step 10 : Notification email address? Step 11 : Set the primary interface speed? [ auto ] Step 12 : Set the primary interface duplex? [ auto ] Step 13 : Would you like to activate the in -path configuration? [ yes ] Step 14 : In-Path IP address? ( 10 .1.30.125 ) Step 15 : In-Path Netmask? 1255 .255.255.01 Step 16 : In-Path Default gateway? [ 10 .1.30.254 ) Step 17 : Set the in -path:LAN interface aspeed? [ auto ] Step 18 : Set the In-path: LAN interface duplex? [ auto ] Step 19 : Set the in -path:WAN interface speed? [ auto ] Step 20 : Set the in -path: WAN Interface duplex? [ auto ]","title":"Riverbed SteelHead configuration wizard"},{"location":"mgmt-and-config/#network-interface-configuration","text":"interface aux description interface aux dhcp interface aux dhcp dynamic-dns no interface aux dhcpv6 no interface aux shutdown interface aux dhcpv6 dynamic-dns interface aux mtu \"1588\" interface aux speed \"auto\" interface inpath8 8 description \"\" no interface inpath8_8 dhcp no interface inpath8 8 dhcp dynamic-dns na interface inpath8_8 dhcpv6 no interface inpath8 8 dhcpv6 dynamic-dns no interface interface inpath0 8 force-Mdi-x enable inpath8_8 ip address 18 .1.58.125 /24 interface inpath8 8 mtu \"1588\" interface interface inpath8_8 napi-weight \"128\" inpath8_8 shutdown interface inpath8_8 speed \"auto\" no interface shutdown inpathB 8 txqueuelen \"188\" lo description","title":"Network interface configuration"},{"location":"quick-notes/","text":"","title":"Quick notes"},{"location":"ssl-tls-traffic/","text":"Accelerate SSL/TLS Traffic Accelerate Encrypted SSL/TLS Traffic Across Complex Defence Network Environments In the past, to optimize and accelerate encrypted traffic and applications involved lengthysecurity conversations, logistical hurdles, sharing orcopying hundreds of certificates and keys, perceived network security risks, and in the end, was often deemed too risky and difficult a process for agencies.Until NowAs encrypted traffic started overtaking public sector networks, Riverbed began reengineering itsoptimization and acceleration solutions to meet thenew norm of SSL/TLS encryption. Riverbed\u2019s enhanced SteelHead WAN Optimization and Client Accelerator solutions simplify the authentication process of SSL/TLS traffic. Client Accelerator now functions like a Hardware Security Module (HSM) by granting access to the \u201csession\u201d key, which is unique and randomly generated, for each encrypted communication session. This novel approach to authentication bypassesthe traditional SSL/TLS \u201chandshake\u201d that requirespublic and private keys and certificates and instead allows encrypted network communications between authorized users and applications within the SteelHead optimization fabric. No sensitive keys orcredentials are ever exchanged or exposed. Once a SSL/TLS session is authenticated and an encrypted connection is established, Defence agencies can easily easily unlock network capacity and improve application performance to meet the ever-growing demands of global users. Breakthrough Performance and Speed for Defense Encrypted Apps and Traffic Benefits of SSL/TLS Acceleration Maintain and strengthen network security postures Achieve zero-touch SSL/TLS optimization and acceleration Unlock critical capacity across any Defense network environment Realize true value of IT investments Transparently operate with mutual authentication (CAC) and advanced TLS (ECDH, PFS) Eliminate certificate management Reduce bandwidth requirements by up to 99% Boost the performance of any on-prem or SaaS SSL/TLS applications by up to 10x Challenges One of the Department of Defense\u2019s Uniformed Services Branches (USB) operates in bandwidth-challenged remote locations across the world where a \u201cLogistics\u201d application, among other mission-critical applications, had been rendered inaccessible due to extreme latency on the Command\u2019s satellite network. Without this application, service technicians could not procure crucial parts needed to repair military assets, resulting in these assets being taken offline and exposing a significant operational vulnerability. Like other Defense agencies, the USB had previously been reluctant to optimize and accelerate its SSL/TLS traffic due to perceived network security concerns. Solution The USB had previously been working with Riverbed to optimize and accelerate its non-encrypted traffic. When evaluating and testing the SSL/TLS-enhanced SteelHead WAN Optimization and Client Accelerator solutions, the USB was easily able to configure and deploy, identify the SSL/TLS application for acceleration, authenticate with the application\u2019s \u201csession\u201d key, and establish encrypted network session. Then the USB employed traditional optimization and acceleration approaches that significantly reduced latency and unlocked network capacity, all while maintaining an encrypted environment. Benefits With Riverbed\u2019s enhanced SteelHead WAN Optimization and Client Accelerator, the USB was able to optimize and accelerate the SSL/TLS traffic unlocking nearly 3x satellite bandwidth capacity. More importantly, the USB was able to bring its mission-critical logistics application online, secure the parts and supplies needed to repair military assets, and support warfighters in the field.","title":"Accelerate SSL/TLS Traffic"},{"location":"ssl-tls-traffic/#accelerate-ssltls-traffic","text":"","title":"Accelerate SSL/TLS Traffic"},{"location":"ssl-tls-traffic/#accelerate-encrypted-ssltls-traffic-across-complex-defence-network-environments","text":"In the past, to optimize and accelerate encrypted traffic and applications involved lengthysecurity conversations, logistical hurdles, sharing orcopying hundreds of certificates and keys, perceived network security risks, and in the end, was often deemed too risky and difficult a process for agencies.Until NowAs encrypted traffic started overtaking public sector networks, Riverbed began reengineering itsoptimization and acceleration solutions to meet thenew norm of SSL/TLS encryption. Riverbed\u2019s enhanced SteelHead WAN Optimization and Client Accelerator solutions simplify the authentication process of SSL/TLS traffic. Client Accelerator now functions like a Hardware Security Module (HSM) by granting access to the \u201csession\u201d key, which is unique and randomly generated, for each encrypted communication session. This novel approach to authentication bypassesthe traditional SSL/TLS \u201chandshake\u201d that requirespublic and private keys and certificates and instead allows encrypted network communications between authorized users and applications within the SteelHead optimization fabric. No sensitive keys orcredentials are ever exchanged or exposed. Once a SSL/TLS session is authenticated and an encrypted connection is established, Defence agencies can easily easily unlock network capacity and improve application performance to meet the ever-growing demands of global users.","title":"Accelerate Encrypted SSL/TLS Traffic Across Complex Defence Network Environments"},{"location":"ssl-tls-traffic/#breakthrough-performance-and-speed-for-defense-encrypted-apps-and-traffic","text":"Benefits of SSL/TLS Acceleration Maintain and strengthen network security postures Achieve zero-touch SSL/TLS optimization and acceleration Unlock critical capacity across any Defense network environment Realize true value of IT investments Transparently operate with mutual authentication (CAC) and advanced TLS (ECDH, PFS) Eliminate certificate management Reduce bandwidth requirements by up to 99% Boost the performance of any on-prem or SaaS SSL/TLS applications by up to 10x","title":"Breakthrough Performance and Speed for Defense Encrypted Apps and Traffic"},{"location":"ssl-tls-traffic/#challenges","text":"One of the Department of Defense\u2019s Uniformed Services Branches (USB) operates in bandwidth-challenged remote locations across the world where a \u201cLogistics\u201d application, among other mission-critical applications, had been rendered inaccessible due to extreme latency on the Command\u2019s satellite network. Without this application, service technicians could not procure crucial parts needed to repair military assets, resulting in these assets being taken offline and exposing a significant operational vulnerability. Like other Defense agencies, the USB had previously been reluctant to optimize and accelerate its SSL/TLS traffic due to perceived network security concerns.","title":"Challenges"},{"location":"ssl-tls-traffic/#solution","text":"The USB had previously been working with Riverbed to optimize and accelerate its non-encrypted traffic. When evaluating and testing the SSL/TLS-enhanced SteelHead WAN Optimization and Client Accelerator solutions, the USB was easily able to configure and deploy, identify the SSL/TLS application for acceleration, authenticate with the application\u2019s \u201csession\u201d key, and establish encrypted network session. Then the USB employed traditional optimization and acceleration approaches that significantly reduced latency and unlocked network capacity, all while maintaining an encrypted environment.","title":"Solution"},{"location":"ssl-tls-traffic/#benefits","text":"With Riverbed\u2019s enhanced SteelHead WAN Optimization and Client Accelerator, the USB was able to optimize and accelerate the SSL/TLS traffic unlocking nearly 3x satellite bandwidth capacity. More importantly, the USB was able to bring its mission-critical logistics application online, secure the parts and supplies needed to repair military assets, and support warfighters in the field.","title":"Benefits"},{"location":"transparency/","text":"Transparency Options Field Carried in EVERY packet, after SYN and SYN/ACK Configured on in-path rules: Can be with Fixed Target (on cli and in-path only) Filter on Wireshark: tcp.options.rvbd.trpy 4e labels packets as \"WAN side Optimized\" for use by: SteelHeads Interceptors SteelCentral devices Contains pseudo Src/Dest IP and ports Effectively NAT/PAT on egress of steelhead Why use different modes? Honestly, in most circumstances, correct addressing is fine however it does depend on the Steel Head deployment method. In SD-WAN environments, full transparency is required so that the SD-WAN policy in place to use a different bearer based on the application or any 5 tuples. Disadvantages of transparency: You lose a feature called Connection pooling, where 20 TCP connections are pre-established between every peer. This skips the need for a 3-way handshake when a session over the WAN is initiated.****","title":"Transparency Options Field"},{"location":"transparency/#transparency-options-field","text":"Carried in EVERY packet, after SYN and SYN/ACK Configured on in-path rules: Can be with Fixed Target (on cli and in-path only) Filter on Wireshark: tcp.options.rvbd.trpy 4e labels packets as \"WAN side Optimized\" for use by: SteelHeads Interceptors SteelCentral devices Contains pseudo Src/Dest IP and ports Effectively NAT/PAT on egress of steelhead","title":"Transparency Options Field"},{"location":"transparency/#why-use-different-modes","text":"Honestly, in most circumstances, correct addressing is fine however it does depend on the Steel Head deployment method. In SD-WAN environments, full transparency is required so that the SD-WAN policy in place to use a different bearer based on the application or any 5 tuples. Disadvantages of transparency: You lose a feature called Connection pooling, where 20 TCP connections are pre-established between every peer. This skips the need for a 3-way handshake when a session over the WAN is initiated.****","title":"Why use different modes?"}]}