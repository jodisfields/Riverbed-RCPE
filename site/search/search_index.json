{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Riverbed RCPE Professional Riverbed RCPE Professional: Implement WAN Optimization Course Notes and Discussion. \ud83e\uddd0 About Riverbed RCPE Professional: Implement WAN Optimization Course Notes and Discussion. This content is intended for personal reference and collaboration only! Course Name: RCPE Professional: Implement WAN Optimization Dates: 23rd - 27th of May 2022 Start time: 0900 NZST 0700 AEST Trainer: Pat Robson \ud83d\udcda Reference Material Riverbed Lab Dashboard Course Specific Labs Zoom Meeting Technet Article \u26cf\ufe0f Built Using Mkdocs Mkdocs Material Markdown Git Python \ud83d\ude80 Deployment Before starting you need to have Git and Python installed. # Clone this project git clone https://github.com/jodisfields/Riverbed-RCPE.git # Access cd Riverbed-RCPE # Install dependencies pip install -r requirements.txt # Run the project mkdocs serve # Open in browser Navigate to http://localhost:8000 \ud83d\udcdd Acknowledgements Riverbed","title":"Home"},{"location":"#about","text":"Riverbed RCPE Professional: Implement WAN Optimization Course Notes and Discussion. This content is intended for personal reference and collaboration only! Course Name: RCPE Professional: Implement WAN Optimization Dates: 23rd - 27th of May 2022 Start time: 0900 NZST 0700 AEST Trainer: Pat Robson","title":"\ud83e\uddd0 About"},{"location":"#reference-material","text":"Riverbed Lab Dashboard Course Specific Labs Zoom Meeting Technet Article","title":"\ud83d\udcda Reference Material"},{"location":"#built-using","text":"Mkdocs Mkdocs Material Markdown Git Python","title":"\u26cf\ufe0f Built Using"},{"location":"#deployment","text":"Before starting you need to have Git and Python installed. # Clone this project git clone https://github.com/jodisfields/Riverbed-RCPE.git # Access cd Riverbed-RCPE # Install dependencies pip install -r requirements.txt # Run the project mkdocs serve # Open in browser Navigate to http://localhost:8000","title":"\ud83d\ude80 Deployment"},{"location":"#acknowledgements","text":"Riverbed","title":"\ud83d\udcdd Acknowledgements"},{"location":"first-lab/","text":"Knowledge check Part 1 In the view below, what informs the connection is optimized? In the view below, what informs the connection is encrypted over the WAN? Calculate the approximate speed for the SMB file transfers, cold and warm. How do they compare to the previous non optimized transfer? Take some time to experiment Hint: hovering icons in your Current Connections screen can answer both Parts... Part 2 1. What was the peak LAN throughput in your timescale for HTTPS traffic? 2. What was it for HTTP and SMB? 3. Why would the optimization effects differ on a \"cold pass\" of one type of data/traffic versus another? Part 3 Note the scale on the Y axis of the chart is automatically adjusted to suit. Hover the mouse over the plot area to display the Data Reduction for various points on the timeline. Note that the LAN Throughput should be greater than WAN Throughput to imply optimization occurring and reducing the amount of throughput on the WAN. 1. What was the peak LAN throughput? 2. When did it happen? 3. What protocol was it? 4. What was the total amount of data that was removed from the WAN during your time period? You have successfully created optimized traffic in an in-path deployment, and should understand the nature of cold and warm file transfers. Ideally you noticed significant improvement in transfer times, even with file modifications. Useful add-on: SDR is protocol agnostic, so the warm transfer of a byte stream in one application will be equally optimized should that byte stream occur in a different applications. As an example, downloading a file from the datacenter via a file share, then sending the file via email; your local and datacenter SteelHeads will see the file 'cold' when downloading, then 'warm' when that same file is attached to an email. Finally, you verified various optimization statistics in different Reports. Good to note that bandwidth reduction/optimization is enabled by default for all TCP ports not explicitly passed through. Once your SteelHead appliance is plugged in and configured with the initial network settings, you can begin optimizing traffic and notice significant performance increase, with accompanying WAN data reduction.","title":"Knowledge check"},{"location":"first-lab/#knowledge-check","text":"","title":"Knowledge check"},{"location":"first-lab/#part-1","text":"In the view below, what informs the connection is optimized? In the view below, what informs the connection is encrypted over the WAN? Calculate the approximate speed for the SMB file transfers, cold and warm. How do they compare to the previous non optimized transfer? Take some time to experiment Hint: hovering icons in your Current Connections screen can answer both Parts...","title":"Part 1"},{"location":"first-lab/#part-2","text":"1. What was the peak LAN throughput in your timescale for HTTPS traffic? 2. What was it for HTTP and SMB? 3. Why would the optimization effects differ on a \"cold pass\" of one type of data/traffic versus another?","title":"Part 2"},{"location":"first-lab/#part-3","text":"Note the scale on the Y axis of the chart is automatically adjusted to suit. Hover the mouse over the plot area to display the Data Reduction for various points on the timeline. Note that the LAN Throughput should be greater than WAN Throughput to imply optimization occurring and reducing the amount of throughput on the WAN. 1. What was the peak LAN throughput? 2. When did it happen? 3. What protocol was it? 4. What was the total amount of data that was removed from the WAN during your time period? You have successfully created optimized traffic in an in-path deployment, and should understand the nature of cold and warm file transfers. Ideally you noticed significant improvement in transfer times, even with file modifications. Useful add-on: SDR is protocol agnostic, so the warm transfer of a byte stream in one application will be equally optimized should that byte stream occur in a different applications. As an example, downloading a file from the datacenter via a file share, then sending the file via email; your local and datacenter SteelHeads will see the file 'cold' when downloading, then 'warm' when that same file is attached to an email. Finally, you verified various optimization statistics in different Reports. Good to note that bandwidth reduction/optimization is enabled by default for all TCP ports not explicitly passed through. Once your SteelHead appliance is plugged in and configured with the initial network settings, you can begin optimizing traffic and notice significant performance increase, with accompanying WAN data reduction.","title":"Part 3"},{"location":"license-tiers/","text":"License Tiers","title":"License Tiers"},{"location":"license-tiers/#license-tiers","text":"","title":"License Tiers"},{"location":"quick-notes/","text":"Quick Notes SteelHead-V Best Practices for Performance Do not share NICS and use at least 1Gbps Allow resources Hypervisor overhead Do not over provision CPU Use a Server Grade CPU for the Hypervisor Always reserve RAM & Virtual RAM < Physical RAM Use SSDs or other high speed disk for the Segstore - Do not share physical disks between hosts Do not use hyperthreading Apply BIOS power settings for maximum performance Steel Head-v and Riverbed Bypass NIC Riverbed Bypass NIC-A physical card for the virtual device. - ESX/ESXI - Direct Path feature - Allows SteelHead-v to contral the bypass hardware: - ESXI driver available from the support website Under related Software - Hyper-V & KVM support Deployment Methods: Physical In-Path LAN & WAN Connected We will look into more detail on: Serial clusters Parallel clusters Simplified Routing Failover Scenarios Deployment Methods: Virtual In-Path WAN physically connected - in-paths interfaces used for optimization We will look into more detail on: Policy-based Routing WCCP Interceptor Layer-4 Switch Deployment Methods - Cloud Optimization Cloud Computing Private cloud: Resources match demand, but can be slow or expensive to adapt Management of resources without restrictions Security Compliance High Availability, but at a cost Public cloud: Scalable and agile Consumer-based billing High Availability Hybrid cloud: As the name implies. Deployment Methods & Network Asymmetry Network Asymmetry Affects Optimization Asymmetric Routing (AR) can be disruptive in optimized environments! SteelHeads need two-way traffic to optimize, regardless of topology: In-path or virtual in-path Virtual in-path can also be a solution, more later As a result: The initial connection will take longer, or even fail SteelHeads will pass through all IP pairs for 24 hours when AR detected. This is to avoid reoccurring fallures -The table can be flushed manually, but must be done on all affected SteelHeads Remember NOTHING happens until we see a SYN message to start optimization Consider manual reset or an auto-kickoff rule Enhanced Auto Discovery (EAD) - Overview Why Use Enhanced? Default since RIOS version 5.5.4 Used to find the LAST Steel Head, not the first Useful on double WAN hops Also useful in serial deployments, but peering rules are much better Faster to fail when the server is not available Faster to detect network asymmetry Why not? May need to be disabled in certain SaaS backhaul deployments, or when overcoming egregious WAN latency such as double satellite Wireshark PCAP of EAD traffic Options: (28 bytes), Maximum segment size, No-Operation (NOP) Maximum segment size: 1460 bytes No-Operation (NOP) Window scale: 8 (multiply by 256) No-Operation (NOP), No-Operation (NOP) TCP SACK Permitted Option: Truel Riverbed Probe: Probe Query, CSH IP: 10.1.120.21 Length: 10 Kind: Riverbed Probe (76) Length: 10 0000... Type: 0 .... 0001 Version: 1 Reserved: 0x01 CSH IP: 10.1.120.21 Application Version: 5 Riverbed Probe: Probe Query Info Length: 4 Kind: Riverbed Probe (76) Length: 4 0000 110. Type: 6 .......8 Version: 2 Probe Flags: 0x21 No-Operation (NOP) End of Option List (EOL) Transparency Options Field Carried in EVERY packet, after SYN and SYN/ACK - Configured on in-path rules: Can be with Fixed Target (on cli and in-path only) - Filter on Wireshark: tcp.options.rvbd.trpy - 4e labels packets as \"WAN side Optimized\" for use by: - SteelHeads - Interceptors - SteelCentral devices - Contains pseudo Src/Dest IP and ports - Effectively NAT/PAT on egress of SH Why use different modes? Honestly, in most circumstances, correct addressing is fine however it does depend on the Steel Head deployment method. In SD-WAN environments, full transparency is required so that the SD-WAN policy in place to use a different bearer based on the application or any 5 tuples. Disadvantages of transparency You lose a feature called Connection pooling, where 20 TCP connections are pre-established between every peer. This skips the need for a 3-way handshake when a session over the WAN is initiated.****","title":"Quick Notes"},{"location":"quick-notes/#quick-notes","text":"","title":"Quick Notes"},{"location":"quick-notes/#steelhead-v-best-practices-for-performance","text":"Do not share NICS and use at least 1Gbps Allow resources Hypervisor overhead Do not over provision CPU Use a Server Grade CPU for the Hypervisor Always reserve RAM & Virtual RAM < Physical RAM Use SSDs or other high speed disk for the Segstore - Do not share physical disks between hosts Do not use hyperthreading Apply BIOS power settings for maximum performance","title":"SteelHead-V Best Practices for Performance"},{"location":"quick-notes/#steel-head-v-and-riverbed-bypass-nic","text":"Riverbed Bypass NIC-A physical card for the virtual device. - ESX/ESXI - Direct Path feature - Allows SteelHead-v to contral the bypass hardware: - ESXI driver available from the support website Under related Software - Hyper-V & KVM support","title":"Steel Head-v and Riverbed Bypass NIC"},{"location":"quick-notes/#deployment-methods-physical-in-path","text":"LAN & WAN Connected We will look into more detail on: Serial clusters Parallel clusters Simplified Routing Failover Scenarios","title":"Deployment Methods: Physical In-Path"},{"location":"quick-notes/#deployment-methods-virtual-in-path","text":"WAN physically connected - in-paths interfaces used for optimization We will look into more detail on: Policy-based Routing WCCP Interceptor Layer-4 Switch","title":"Deployment Methods: Virtual In-Path"},{"location":"quick-notes/#deployment-methods-cloud-optimization-cloud-computing","text":"Private cloud: Resources match demand, but can be slow or expensive to adapt Management of resources without restrictions Security Compliance High Availability, but at a cost Public cloud: Scalable and agile Consumer-based billing High Availability Hybrid cloud: As the name implies.","title":"Deployment Methods - Cloud Optimization Cloud Computing"},{"location":"quick-notes/#deployment-methods-network-asymmetry","text":"Network Asymmetry Affects Optimization Asymmetric Routing (AR) can be disruptive in optimized environments! SteelHeads need two-way traffic to optimize, regardless of topology: In-path or virtual in-path Virtual in-path can also be a solution, more later As a result: The initial connection will take longer, or even fail SteelHeads will pass through all IP pairs for 24 hours when AR detected. This is to avoid reoccurring fallures -The table can be flushed manually, but must be done on all affected SteelHeads Remember NOTHING happens until we see a SYN message to start optimization Consider manual reset or an auto-kickoff rule","title":"Deployment Methods &amp; Network Asymmetry"},{"location":"quick-notes/#enhanced-auto-discovery-ead-overview-why-use-enhanced","text":"Default since RIOS version 5.5.4 Used to find the LAST Steel Head, not the first Useful on double WAN hops Also useful in serial deployments, but peering rules are much better Faster to fail when the server is not available Faster to detect network asymmetry Why not? May need to be disabled in certain SaaS backhaul deployments, or when overcoming egregious WAN latency such as double satellite","title":"Enhanced Auto Discovery (EAD) - Overview Why Use Enhanced?"},{"location":"quick-notes/#wireshark-pcap-of-ead-traffic","text":"Options: (28 bytes), Maximum segment size, No-Operation (NOP) Maximum segment size: 1460 bytes No-Operation (NOP) Window scale: 8 (multiply by 256) No-Operation (NOP), No-Operation (NOP) TCP SACK Permitted Option: Truel Riverbed Probe: Probe Query, CSH IP: 10.1.120.21 Length: 10 Kind: Riverbed Probe (76) Length: 10 0000... Type: 0 .... 0001 Version: 1 Reserved: 0x01 CSH IP: 10.1.120.21 Application Version: 5 Riverbed Probe: Probe Query Info Length: 4 Kind: Riverbed Probe (76) Length: 4 0000 110. Type: 6 .......8 Version: 2 Probe Flags: 0x21 No-Operation (NOP) End of Option List (EOL)","title":"Wireshark PCAP of EAD traffic"},{"location":"quick-notes/#transparency-options-field","text":"Carried in EVERY packet, after SYN and SYN/ACK - Configured on in-path rules: Can be with Fixed Target (on cli and in-path only) - Filter on Wireshark: tcp.options.rvbd.trpy - 4e labels packets as \"WAN side Optimized\" for use by: - SteelHeads - Interceptors - SteelCentral devices - Contains pseudo Src/Dest IP and ports - Effectively NAT/PAT on egress of SH","title":"Transparency Options Field"},{"location":"quick-notes/#why-use-different-modes","text":"Honestly, in most circumstances, correct addressing is fine however it does depend on the Steel Head deployment method. In SD-WAN environments, full transparency is required so that the SD-WAN policy in place to use a different bearer based on the application or any 5 tuples. Disadvantages of transparency You lose a feature called Connection pooling, where 20 TCP connections are pre-established between every peer. This skips the need for a 3-way handshake when a session over the WAN is initiated.****","title":"Why use different modes?"}]}